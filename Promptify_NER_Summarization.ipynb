{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HhNZ9PRTgxM"
      },
      "outputs": [],
      "source": [
        "# Install all the required libraries for Speech-to-text and speaker diarization\n",
        "%%capture\n",
        "!git clone https://github.com/promptslab/Promptify.git\n",
        "!pip3 install openai\n",
        "!pip install tiktoken\n",
        "!pip install openai -q\n",
        "!pip install huggingface_hub\n",
        "!pip install bert_score\n",
        "!pip install anthropic\n",
        "!pip install cohere\n",
        "!pip install --upgrade PyPDF2 python-docx\n",
        "\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1VTSg8XUATO"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "%cd /content/Promptify\n",
        "import numpy as np\n",
        "from bert_score import BERTScorer, score\n",
        "from transformers import DebertaTokenizer, DebertaModel\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import torch\n",
        "from promptify import OpenAI, Prompter\n",
        "from pprint import pprint\n",
        "from IPython.display import Markdown, display\n",
        "from IPython.core.display import display, HTML\n",
        "import time\n",
        "import openai\n",
        "import os\n",
        "import re\n",
        "import ast\n",
        "import nltk\n",
        "import json\n",
        "import glob\n",
        "from docx import Document\n",
        "from PyPDF2 import PdfReader\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIo9Kl9vnKAq",
        "outputId": "da5981a2-a60f-436b-f4ee-19e82c2fe0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#OpenAI API key. [PN: I have removed my token purposefully due to privacy restrictions from Grantify Limited]\n",
        "api_key  = \"sk-\"\n",
        "\n",
        "# Create an instance for the OpenAI model, Currently supporting Openai's all model, In future adding more generative models from Hugginface and other platforms\n",
        "model = OpenAI(api_key)\n",
        "nlp_prompter = Prompter(model)\n",
        "\n",
        "# Mount the path where the audio files(input files) are stored\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgZU6TA1ZSpH"
      },
      "outputs": [],
      "source": [
        "# Function to extract entities using chapt GPT 4\n",
        "def get_entities_question_guide_openai(question, guideline, MODEL=\"gpt-4\"):\n",
        "    time.sleep(1)\n",
        "\n",
        "    if not question or not guideline:\n",
        "      return \"\"\n",
        "\n",
        "    system_role = \"You are an helpful agent that performs named entity recognition (NER) on the given text and show a list of comma separated entity types. Output empty string of no entities are present.\"\n",
        "    user_role = f\"Given the QUESTION and GUIDLINES, predict different named entities that are present in the text. Only show the complete named entity type in comma separated way:\\n\"\n",
        "    input_text = f\"QUESTION: {question} \\nGUIDELINES: {guideline}\"\n",
        "    completions = openai.ChatCompletion.create(\n",
        "                model = MODEL,\n",
        "                messages = [\n",
        "                    {'role': 'system', 'content': system_role},\n",
        "                    {'role': 'user', 'content': user_role + input_text},\n",
        "                ],\n",
        "                temperature = 0\n",
        "                )\n",
        "    output = completions['choices'][0]['message']['content']\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDmo3OKGNVxp"
      },
      "outputs": [],
      "source": [
        "# Function to execute the prompt as input using OpenAI chapt GPT 4\n",
        "def openai_chat_completion_response(final_prompt):\n",
        "  response = openai.ChatCompletion.create(\n",
        "              model=\"gpt-4\",\n",
        "              messages=[\n",
        "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                    {\"role\": \"user\", \"content\": USER_PROMPT_1},\n",
        "                    {\"role\": \"assistant\", \"content\": ASSISTANT_PROMPT_1},\n",
        "                    {\"role\": \"user\", \"content\": final_prompt}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "  return response['choices'][0]['message']['content'].strip(\" \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgyG2riHipVI"
      },
      "outputs": [],
      "source": [
        "# Code block to convert docx of pdf files to txt format\n",
        "def convert_pdf_to_txt(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf = PdfReader(file)\n",
        "        text = ''\n",
        "        for page in range(len(pdf.pages)):\n",
        "            text += pdf.pages[page].extract_text().strip() + '\\n'\n",
        "        return text\n",
        "\n",
        "def convert_word_to_txt(word_path):\n",
        "    doc = Document(word_path)\n",
        "    text = ''\n",
        "    for paragraph in doc.paragraphs:\n",
        "        text += paragraph.text + '\\n'\n",
        "    return text\n",
        "\n",
        "def convert_documents_to_txt(folder_path):\n",
        "    files = glob.glob(os.path.join(folder_path, '*'))\n",
        "    for file_path in files:\n",
        "      print('0')\n",
        "      if file_path.endswith('.pdf'):\n",
        "          print('1')\n",
        "          text = convert_pdf_to_txt(file_path)\n",
        "          txt_path = os.path.splitext(file_path)[0] + '.txt'\n",
        "          with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
        "              txt_file.write(text)\n",
        "          print(f'Converted {file_path} to {txt_path}')\n",
        "      elif file_path.endswith('.docx'):\n",
        "          text = convert_word_to_txt(file_path)\n",
        "          txt_path = os.path.splitext(file_path)[0] + '.txt'\n",
        "          with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
        "              txt_file.write(text)\n",
        "          print(f'Converted {file_path} to {txt_path}')\n",
        "      else:\n",
        "          print(f'Skipped {file_path} (unsupported file format)')\n",
        "\n",
        "\n",
        "# Provide the folder path containing PDF and Word documents\n",
        "folder_path = \"/content/drive/MyDrive/Audio_Transcripts/\"\n",
        "print('Folder Path:',folder_path)\n",
        "convert_documents_to_txt(folder_path)\n",
        "print('Done')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Audio_Transcripts/GMT20230222-115812_Recording.transcript_txt.txt\""
      ],
      "metadata": {
        "id": "BKh1wTuCwUAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4753GvLNU5J"
      },
      "outputs": [],
      "source": [
        "# Code for entity extraction\n",
        "def read_large_file(filename, chunk_size):\n",
        "    with open(filename, 'rb') as file:\n",
        "        chunk = ''\n",
        "        while True:\n",
        "            # Read chunk_size number of characters from the file\n",
        "            data = file.read(chunk_size)\n",
        "            # Convert the content to a string\n",
        "            data = data.decode('utf-8')\n",
        "\n",
        "            # Break the loop if the end of the file is reached\n",
        "            if not data:\n",
        "                break\n",
        "\n",
        "            # Append the current chunk to the overall chunk\n",
        "            chunk += data\n",
        "\n",
        "            # Split the chunk into separate tokens (e.g., words)\n",
        "            tokens = chunk.split()\n",
        "\n",
        "            # Check if the last token is complete or partial\n",
        "            last_token = tokens[-1]\n",
        "            last_token_length = len(last_token)\n",
        "\n",
        "            # If the last token is complete, yield the chunk and reset it\n",
        "            if last_token_length == chunk_size:\n",
        "                yield chunk\n",
        "                chunk = ''\n",
        "\n",
        "            # If the last token is partial, remove it from the chunk\n",
        "            elif last_token_length < chunk_size:\n",
        "                chunk = ' '.join(tokens[:-1]) + ' '\n",
        "\n",
        "        # Yield the remaining chunk (if any)\n",
        "        if chunk:\n",
        "            yield chunk\n",
        "\n",
        "# Example usage\n",
        "\n",
        "chunk_size = 8000\n",
        "\n",
        "for chunk in read_large_file(filename, chunk_size):\n",
        "    print('CHUNKKKKKKKK',len(chunk))\n",
        "    # Split the chunk into smaller subchunks of maximum allowed length\n",
        "    subchunks = [chunk[i:i+8192] for i in range(0, len(chunk), 8192)]\n",
        "    print('subchunk:',len(subchunks))\n",
        "    k=0\n",
        "    for subchunk in subchunks:\n",
        "        print(\"k\",k)\n",
        "        k=k+1\n",
        "        print(\"subchunk:\",subchunk)\n",
        "        # Do something with each subchunk (e.g., process it)\n",
        "\n",
        "        SYSTEM_PROMPT = \"You are a smart and intelligent Named Entity Recognition (NER) system. I will provide you the definition of the entities you need to extract and the sentence from which you need to extract the entities and the output in given format with examples, but do not use the examples as the actual output.\"\n",
        "\n",
        "        USER_PROMPT_1 = \"Are you clear about your role?\"\n",
        "\n",
        "        ASSISTANT_PROMPT_1 = \"Sure, I'm ready to help you with your NER task. Please provide me with the necessary information to get started.\"\n",
        "\n",
        "        PROMPT = (\n",
        "            \"Entity Definition:\\n\"\n",
        "            \"1. Company name: The official name by which a company is registered and known legally. It is the unique identifier for a company and is used in various official documents and communications like Google, samsung, Apple etc.\\n\"\n",
        "            \"2. Company incorporation date: This refers to the date when a company is officially formed and registered with the appropriate government authority. It marks the starting point of the company's legal existence. Dates can also be in natural language.\\n\"\n",
        "            \"3. Company registration number: It is a unique alphanumeric identifier assigned to a company by the government authority responsible for registering companies. This number is used for official purposes, such as taxation, legal filings, and identification of the company in various records.\\n\"\n",
        "            \"4. Unique Taxpayer Reference: It is a unique identifier assigned to an individual or company by the tax authority in the United Kingdom, Her Majesty's Revenue and Customs (HMRC). It is also called as UTR. The UTR is used to track and manage tax obligations, including R&D tax credits, for the entity associated with it. It is important to note that UTR specifically refers to the UK tax system and may have similar equivalents in other countries.\\n\"\n",
        "            \"5. Accounting period: It refers to the specific timeframe during which a company's eligible research and development expenses are assessed for the purpose of claiming tax credits. It is the period for which financial records and transactions are prepared and reported to determine the qualifying R&D activities and associated expenses.\\n\"\n",
        "            \"6. Client email: The email address associated with a client or customer involved in the R&D project for communication purposes.\\n\"\n",
        "            \"7. Confirm Ltd Company: Confirmation of whether the company is a limited company, which is a legal business structure with limited liability for its shareholders. The answer should be a yes or no.\\n\"\n",
        "            \"8. Confirm SME: Confirmation of whether the company meets the criteria of a small or medium-sized enterprise (SME) which typically includes having fewer than 500 employees and an annual turnover below £100 million. (Conditions: <500 employees, <£100m annual turnover). The answer should be a yes or no.\\n\"\n",
        "            \"9. Confirm no other government grants/subsidies in past 3 periods: Confirmation of whether the company or claimant has received any other government grants or subsidies during the previous three accounting periods. The answer should be a yes if the company or claimant received any grants or subsidies and a no if not received.\\n\"\n",
        "            \"10. Confirm no linked enterprises: Confirmation of whether the company has any linked enterprises, indicated by either owning more than 50% of another business or having another company own more than 50% of the company. The answer should be a yes or no.\\n\"\n",
        "            \"11. Confirm no partner enterprises: Confirmation of whether the company has any partner enterprises, indicated by either owning between 25% and 50% of another company or having another company own between 25% and 50% of the company. The answer should be a yes or no.\\n\"\n",
        "            \"12. Industry Classification: You are an industry classification expert assisting a client in determining the industry classification for their business. Your client provides you with a brief description of their business, and you are tasked with identifying and classifying the industry in which their business operates. Provide a detailed response explaining the industry classification and the factors that contribute to it.\"\n",
        "            \"13. Elevator Pitch: You are a marketing consultant working with a client who needs help crafting an effective elevator pitch for their business. The client provides you with a brief description of their business, and you are tasked with creating a compelling elevator pitch that succinctly conveys the unique value proposition and key benefits of their business. Write an elevator pitch that captures the essence of their business and highlights its competitive advantage, target audience, and main offerings in a concise and persuasive manner.\"\n",
        "            \"14. Name of CTO:You are an R&D tax credits consultant working with a company to help them navigate the process of claiming R&D tax credits. The company seeks assistance in providing the name of their Chief Technology Officer (CTO) for inclusion in the tax credit application. Write a response guiding them on how to identify and document the CTO's name within the specific context of R&D tax credits, considering their role and responsibilities in driving the company's technological and innovation strategies.\"\n",
        "            \"15. Experience and/or Qualifications: It refers to the expertise and qualifications of individuals involved in the company's research and development activities. These competent professionals play a crucial role in driving and overseeing the R&D projects that qualify for tax credits.\"\n",
        "            \"16. Team Member 1: You are an R&D tax credits consultant assisting a company in preparing their R&D tax credit claim. The company requires information about Team Member 1, including their name, role, and experience/qualifications.\"\n",
        "            \"17. Team Member 2: You are an R&D tax credits consultant assisting a company in preparing their R&D tax credit claim. The company requires information about Team Member 2, including their name, role, and experience/qualifications.\"\n",
        "            \"\\n\"\n",
        "            \"Output Format:\\n\"\n",
        "            \"{{'Company name': [list of entities present], 'Company incorporation date': [list of entities present], 'Company registration number': [list of entities present],'Unique Taxpayer Reference': [list of entities present], 'Accounting period': [list of entities present], 'Client email': [list of entities present], 'Confirm Ltd Company': [list of entities present], 'Confirm SME': [list of entities present], 'Confirm no other government grants/subsidies in past 3 periods': [list of entities present], 'Confirm no linked enterprises': [list of entities present], 'Confirm no partner enterprises': [list of entities present], 'Industry Classification': [list of entities present], 'Elevator Pitch': [list of entities present], 'Name of CTO': [list of entities present], 'Experience and/or Qualifications': [list of entities present], 'Team Member 1': [list of entities present], 'Team Member 2': [list of entities present]}}\\n\"\n",
        "            \"If no entities are presented in any categories keep it None\\n\"\n",
        "            \"\\n\"\n",
        "            \"Examples:\\n\"\n",
        "            \"\\n\"\n",
        "            \"1. Sentence: *(Here I have provide appropriate example of the Grantify's client to the OpenAI model. I have removed this example due to provacy restrictions from Grantify Limited.)*\\n\"\n",
        "\n",
        "            \"Output: {{'Company name': ['ABC Ltd'], 'Company incorporation date': ['31st March 2022'], 'Company registration number': ['XYZ'],'Unique Taxpayer Reference':['PQR'], 'Accounting period': ['31st March 2022'], 'Client email': ['None'],'Confirm Ltd Company': ['yes'],'Confirm SME': ['yes'], 'Confirm no other government grants/subsidies in past 3 periods': ['No'], 'Confirm no linked enterprises': [''], 'Confirm no partner enterprises': [''], 'Industry Classification': [ 'Renewable Energy', 'Hydropower Generation'], 'Elevator Pitch': ['At Kinetic Hydro Ltd, we're revolutionizing access to electricity for underserved communities worldwide. Our innovative river turbines harness the untapped energy resource of flowing water, providing continuous (baseload) power that contributes to the energy security of rural areas. With easy transportation, installation, and maintenance, our turbines are designed specifically for remote locations. By offering a cost-effective alternative to grid expansion, we address the pressing energy access needs in Sub Saharan Africa and South and East Asia. Join us in powering the future sustainably and making a meaningful impact on the lives of millions.'], 'Name of CTO': ['None'], 'Experience and/or Qualifications': ['None'], 'Team Member 1': ['Dr Richard Montague, Director and Engineer, over 17 years experience'], 'Team Member 2': ['Donald Naylor, Director and Engineer, over 20 years experience'], 'Team Member 3': ['Raafey Andrabi, Engineering Intern'] }}\\n\"\n",
        "            \"\\n\"\n",
        "\n",
        "            \"2. Sentence: {}\\n\"\n",
        "            \"Output: \"\n",
        "        )\n",
        "\n",
        "        PROMPT = PROMPT.format(subchunk)\n",
        "        ners = openai_chat_completion_response(PROMPT)\n",
        "        print(ners)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR4kE6yE04rz"
      },
      "outputs": [],
      "source": [
        "# Logic for text Summarization and semantic similarity analysis starts from here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for getting DeBERTa similarity\n",
        "\n",
        "def compute_similarity_deberta(sentence1, sentence2):\n",
        "    # Tokenize input sentences\n",
        "    encoded_input = tokenizer.encode_plus(sentence1, sentence2, padding='longest', truncation=True, return_tensors='pt')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Obtain the DeBERTa embeddings for the input sentences\n",
        "        outputs = model_deberta(**encoded_input)\n",
        "        embeddings = outputs.last_hidden_state.squeeze(0)\n",
        "\n",
        "    # Compute cosine similarity between the embeddings\n",
        "    similarity_score = torch.nn.functional.cosine_similarity(embeddings[0], embeddings[1], dim=0).item()\n",
        "    return similarity_score\n",
        "\n",
        "def compute_similarity_matrix_deberta(candidate_list, reference_list):\n",
        "    similarity_matrix = []\n",
        "    for candidate in candidate_list:\n",
        "        row = []\n",
        "        for reference in reference_list:\n",
        "            similarity_score = compute_similarity_deberta(candidate, reference)\n",
        "            row.append(similarity_score)\n",
        "        similarity_matrix.append(row)\n",
        "    return similarity_matrix\n",
        "\n",
        "# Load DeBERTa model and tokenizer\n",
        "model_name_deberta = 'microsoft/deberta-base'\n",
        "tokenizer = DebertaTokenizer.from_pretrained(model_name_deberta)\n",
        "model_deberta = DebertaModel.from_pretrained(model_name_deberta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "3ec8bd7ba90148adaa362fe28b933396",
            "16a844f2a27443d29e917e7d3c0f3b69",
            "7df7bde07ef5450eaf1060e4d166b33e",
            "1b37f16daebf4c22855511e11986be7a",
            "e44b1ddf14ef4f49b8088cacfc2fc4a4",
            "dca5b9a8b87e4d2a8cda44cada183103",
            "21873e8dcedc4b38a53cc7508695bbd6",
            "f219a8b91e5b4ff1b52c7785ca3dc51f",
            "2aa012c9bf464567a1496097f1020ed1",
            "814d3e9670b64b1caed1adfe6eb47d5c",
            "44eca686ccd04012a9920796b1bb6c58",
            "8f0098d9464c4af8bf7328fdf11f1d72",
            "1363a8da9e8049868f614b5090959aba",
            "70d39656624145ff8eec5034793e2871",
            "2b25e46c29154ee99d656ae6ca13e560",
            "d10dbd7afc6e4640b8cf3af1bcce016c",
            "435ef9befd1446be9af3411bede06fc5",
            "9f7692ec0083497c9870fe100a464ea5",
            "0513d1758b97407fa23afaa42daef3e1",
            "d8072269805944d09036ee8d0a082985",
            "6320e176eaf7412cb7a5616d2c4b19ad",
            "0ca43c56a01746a988c62c94f047df8e",
            "3748c1b4a6744ed9bc548d9444a86fd5",
            "65bb86e04c3c45c7bc0b2bc229029637",
            "2d6fb11ee95c4d7799da471225367361",
            "bafdee40f6dc4174a50725779bbbd4e0",
            "83bad556f2424ac69724dc22338c6f6e",
            "53aee82f98b646c699216d0c13baf836",
            "2bcf803878344af5bb9059a4ecb23be8",
            "66d12798d08c41eaac40ca3e0e0f3bc6",
            "41ddfda1a5414a36a9e169db499e92f9",
            "a4695349d14a4b5e915f65c7fd8fe9c3",
            "805d3bc0b91e4935a2a2b824f8474790",
            "412b795aa587401f992ee58016c1e663",
            "26a9938c2b8e477499ba679d799a3098",
            "37b0b8d65cea49198f75f025ceabf0c6",
            "b1bab71e7e3645fa83943d4179969804",
            "f3028f8db5734480b93f8e7412334335",
            "4d3d4e87c6b64299b3433d135beccd9d",
            "4f115b299bbb4c4996bd93c3bacd30f5",
            "76347ebc65f84d18b165905c6f1c113f",
            "ec751ada77f64224aeaf17017df5e19c",
            "a1d4aa6664c649219a8e8e91066005f1",
            "4e7424358e4b4d28b829b9f4537eb371",
            "0bdc0fd4cad1445da4fb0396f7d12485",
            "5c9b9709c9624b8ebb25f3cdbc63acea",
            "bacfd963bb274f7aa189f7ab2b4d4a68",
            "5237fbb394f8420c989236746ee52cc8",
            "de38cd4b904c4a7586945dd9aae30d58",
            "cdc7dbcaa50c4d0c9775fc6eff4d77f6",
            "f10bb1d3c2f94ad7905f7bdeadb7c10e",
            "97b1343565954902b660639a516d8dcd",
            "f3bbdc8ea9374e29a69c8cf32b4e356b",
            "53107e0f24114188ba3edcd65b040c26",
            "a5be0dd206c9476488c24c3dec4be359"
          ]
        },
        "id": "Wdu_xT3FTaZg",
        "outputId": "f29b0074-bb55-40ba-dee7-c466c5a28cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ec8bd7ba90148adaa362fe28b933396"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f0098d9464c4af8bf7328fdf11f1d72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3748c1b4a6744ed9bc548d9444a86fd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "412b795aa587401f992ee58016c1e663"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/559M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bdc0fd4cad1445da4fb0396f7d12485"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for getting RoBERTa similarity\n",
        "\n",
        "def compute_similarity_roberta(sentence1, sentence2):\n",
        "    encoded_input = tokenizer(sentence1, sentence2, return_tensors='pt', truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model_roberta(**encoded_input)\n",
        "    logits = outputs.logits\n",
        "    softmax = torch.softmax(logits, dim=1)\n",
        "    similarity_score = softmax[0][1].item()\n",
        "    return similarity_score\n",
        "\n",
        "def compute_similarity_matrix_roberta(candidate_list, reference_list):\n",
        "    similarity_matrix = []\n",
        "    for candidate in candidate_list:\n",
        "        row = []\n",
        "        for reference in reference_list:\n",
        "            similarity_score = compute_similarity_roberta(candidate, reference)\n",
        "            row.append(similarity_score)\n",
        "        similarity_matrix.append((candidate, reference, similarity_score))\n",
        "    return similarity_matrix\n",
        "\n",
        "model_name_roberta = 'roberta-base'\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name_roberta)\n",
        "model_roberta = RobertaForSequenceClassification.from_pretrained(model_name_roberta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "67ecbb59ac554cabbaf18f40d4cd126b",
            "3ab0f18e0a3043f284af3fcabbcab519",
            "cd22d6b3bf8642dea81f0321c6a36dd5",
            "45cfd8dfd82d4e20934365fa91b15118",
            "f745d8b53d4840359dfa5401bf6be547",
            "198b3f9631b14f7f93baa341cf7881e3",
            "71497ae387de4c90912a84c28770e0db",
            "8828fe84e40042da9193ce09d7c3d37b",
            "52323df5055e4040b4248810f557249c",
            "0ccda1df799848c69539b7e70952357f",
            "0c4fa454397c462a98d32d80d8a8b8b7",
            "dc9b89bdd935417f802f21030c206f2f",
            "4f12d5516bb841188d84d17693fa51ff",
            "abf19a33308a49e29e4bddceee784ca8",
            "8e2612f7cb2d42918ed3d8829d272e9a",
            "79a8e51f5dc140aba4b95f8c657c4858",
            "fc9cc9de40464ae0a08e69fc829a1430",
            "0506dd21daf147bf98dc3bf8218c0741",
            "f09c6561661b486699f3801c01618f29",
            "e2ed6e83fe134129a794340a0e959dad",
            "feadc59b9bb545088222624b3ae39440",
            "4199e5823f6a457f8c3f1c12fec48752",
            "6f46795560d549a187870491edb5c913",
            "306b293bb30e49d9ac015c022bea57d6",
            "e5b3bfa6f49149a787d42dce37403079",
            "cf2dad354dd345559e9a0cbf978ec642",
            "3b9b7c3b22ea45448b501695ab571cd3",
            "08222869cfd54adf8327231dbc349052",
            "41612e156a154ef0b111d1eb70511910",
            "9f28b318d1a049228ac5785e857ab53e",
            "bb10bc208c4b4f40a3ef8d5dd7fdf2c6",
            "c5999978cb1748318543f4c042a784ab",
            "ef8dbdfe94084ee6a9a7d6772cdb503d",
            "0733322784a740c8b8c1a77e19eadbf5",
            "59c2a1ce4dce42c9a7e8719eba83c728",
            "45a0a1c727ce4bce8c6013b613ae9940",
            "1b245470371e4b24a8c02fb35a8aac94",
            "d3a544da2a4e4b4d9234af21fe5ccb8a",
            "d6f035f3a215485e8522b45cf081d9d2",
            "2902dad3d41e4526b93ff16fcf96fe08",
            "39e48843854c4baaa6c3ba8504b5a799",
            "b4348fc0faf543e5a2e89e1d165a35f9",
            "bdf4db1ba2114dd4b560fb2003259b8c",
            "d7f576b54a8346b3890b22c6e2a3ebdc"
          ]
        },
        "id": "BaL-8-9sTaxO",
        "outputId": "3ada293d-8fe6-4aea-dbae-1c1b74bb8e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67ecbb59ac554cabbaf18f40d4cd126b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc9b89bdd935417f802f21030c206f2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f46795560d549a187870491edb5c913"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0733322784a740c8b8c1a77e19eadbf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-uFbHf0s5hb"
      },
      "outputs": [],
      "source": [
        "# BERTScore Implementation - Evaluation metric for Summarization\n",
        "def generate_bert_score(cands, refs):\n",
        "  sentences_cands = nltk.sent_tokenize(cands)\n",
        "\n",
        "  # list_of_sentences_cands = [sentence.split() for sentence in sentences_cands]\n",
        "\n",
        "  print(sentences_cands)\n",
        "\n",
        "  sentences_refs = nltk.sent_tokenize(refs)\n",
        "\n",
        "  # list_of_sentences_refs = [sentence.split() for sentence in sentences_refs]\n",
        "\n",
        "  list_of_lists_refs = [sentences_refs.copy() for _ in range(len(sentences_refs))]\n",
        "\n",
        "  print(list_of_lists_refs)\n",
        "\n",
        "  # print(sentences_refs)\n",
        "\n",
        "  scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
        "  P, R, F1 = scorer.score(sentences_cands, list_of_lists_refs)\n",
        "\n",
        "  print(\"F1 Score:\",F1)\n",
        "  print(\"F1 Mean Score:\",F1.mean())\n",
        "\n",
        "  return F1, F1.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq4Eumw6teH4"
      },
      "outputs": [],
      "source": [
        "# function for generating the summary by applying the HMRC guidelines to the summary generated. This is used for answers 3, 4 and 5.\n",
        "def apply_hmrc_guidelines(full_summary, hmrc_reference):\n",
        "    prompt = f\"Summary: {full_summary}\\nReference: {hmrc_reference}\\nQuestion: {question}\\nApply HMRC guidelines to modify the summary according on the prompts mentioned in the question:\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=1024,\n",
        "        temperature=0.7,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        timeout=10\n",
        "    )\n",
        "\n",
        "    modified_summary = response.choices[0].message.content.strip().split(\"Summary: \")[-1]\n",
        "    return modified_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhieuqZ0aXD0"
      },
      "outputs": [],
      "source": [
        "# function for extracting text from the call transcription file i.e., the input file\n",
        "def extract_text(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "# Provide the path to your text file\n",
        "file_path = filename\n",
        "\n",
        "# Call the function to extract the text\n",
        "extracted_text = extract_text(file_path)\n",
        "\n",
        "# Print the extracted text\n",
        "print(extracted_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R05MfknE08wC"
      },
      "outputs": [],
      "source": [
        "# extract the words by splitting at space as a delimiter\n",
        "words = extracted_text.split(\" \")\n",
        "\n",
        "# show the first 20 words\n",
        "words[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Lm5FYo908JJ"
      },
      "outputs": [],
      "source": [
        "# create an array of 6 words as a chunk to be suitable for processing\n",
        "chunks = np.array_split(words, 6)\n",
        "\n",
        "chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN-wZ6vk07cw"
      },
      "outputs": [],
      "source": [
        "sentences = ' '.join(list(chunks[0]))\n",
        "\n",
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7W3kgDO060A"
      },
      "outputs": [],
      "source": [
        "# sample run\n",
        "prompt = f\"{sentences}\\n\\ntl;dr:\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0.3, # The temperature controls the randomness of the response, represented as a range from 0 to 1. A lower value of temperature means the API will respond with the first thing that the model sees; a higher value means the model evaluates possible responses that could fit into the context before spitting out the result.\n",
        "    max_tokens=1024,\n",
        "    top_p=1, # Top P controls how many random results the model should consider for completion, as suggested by the temperature dial, thus determining the scope of randomness. Top P’s range is from 0 to 1. A lower value limits creativity, while a higher value expands its horizons.\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=1\n",
        ")\n",
        "\n",
        "response_text=response.choices[0].message.content\n",
        "response_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otmYVgXq06NA"
      },
      "outputs": [],
      "source": [
        "# Code block for text summariZation for question 1\n",
        "summary_responses = []\n",
        "\n",
        "question = \"\"\"Prompt:\n",
        "\n",
        "Please provide information regarding the introduction and background of the company, including the incorporation date, registration number, reference number, company background, innovative solution, and any research and development (R&D) tax relief.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Incorporation Date:\n",
        "Please provide the date when the company was incorporated.\n",
        "Registration Number:\n",
        "Kindly provide the registration number of the company as recorded at the relevant regulatory authority.\n",
        "Reference Number for Corporation Tax Returns:\n",
        "Please provide the reference number under which the company submits its annual corporation tax returns.\n",
        "Company Background:\n",
        "Describe the background of the company, including its industry, purpose, and key operations.\n",
        "Innovative Solution:\n",
        "Describe the innovative solution or product developed by the company, emphasizing its unique features and value proposition.\n",
        "Research and Development (R&D) Tax Relief:\n",
        "Please provide details about any research and development (R&D) tax relief or incentives that the company has applied for or utilized, including the applicable reference or eligibility criteria.\n",
        "Please provide the information in separate sections as described above.\"\"\"\n",
        "\n",
        "for chunk in chunks:\n",
        "    sentences = ' '.join(list(chunk))\n",
        "    concatenated_string = \", \".join([str(item) for item in summary_responses]) + sentences  # prepend the summary for each chunk\n",
        "\n",
        "    prompt = f\"\"\"Summarize the Transcription including the key points: incorporation date, Registration Number, Reference Number for Corporation Tax Returns, Company Background,\n",
        "    Innovative Solution and Accounting period.\n",
        "    The Company Background and Innovative Solution should be summarized with 200 words out of a total of a maximum of 300 words \\nTranscription: {concatenated_string}\\n\\ntl;dr:\"\"\"\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.3, # The temperature parameter controls the randomness attribute of the response, represented as a range from 0 to 1. A lower value of temperature indicates that the API will respond with the first thing that the model sees; a higher value indicates the model evaluates possible responses which could fit into the context before outputting out the result.\n",
        "        max_tokens=1024,\n",
        "        top_p=1, # Top P parameter controls how many random results the model should consider for model completion, as suggested by the temperature parameter, thus determining the scope of randomness. Top P’s range is from 0 to 1. A lower value imposes limitation on creativity, while a higher value expands its horizons for creativity.\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=1\n",
        "    )\n",
        "\n",
        "    response_text = response[\"choices\"][0][\"text\"]\n",
        "    summary_responses.append(response_text)\n",
        "\n",
        "full_summary_q1 = \"\".join(response_text)\n",
        "\n",
        "print(\"full summary for q1:\")\n",
        "print(full_summary_q1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvtIaSAy04HN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f2b51b-6642-4879-d659-7337152fbd18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: tensor([0.5500, 0.4950, 0.5089, 0.5206, 0.5180, 0.4900, 0.5156, 0.6791])\n",
            "F1 Mean Score: tensor(0.5345)\n",
            "F1_q1, Mean F1 q1: tensor([0.6000, 0.5950, 0.6089, 0.6206, 0.6180, 0.5900, 0.6156, 0.5791]) tensor(0.5345)\n"
          ]
        }
      ],
      "source": [
        "# Code block for generate BERT score for question 1\n",
        "# Include the candidate reference form the manually created output report\n",
        "cands_q1 = '''*(From the manually created output report, I have included the section corresponding to the question 1 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q1, F1_mean_q1 = generate_bert_score(cands_q1, full_summary_q1)\n",
        "\n",
        "print('F1_q1, Mean F1 q1:',F1_q1, F1_mean_q1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to tokenize paragraohs to sentences-used by DeBERTa and RoBERTa\n",
        "def paragraph_to_sentences(paragraph):\n",
        "    sentences = nltk.sent_tokenize(paragraph)\n",
        "    return sentences\n",
        "# Converting candidate and reference paragraphs to list of sentences using the above mentioned function 'paragraph_to_sentences'\n",
        "candidate_list = paragraph_to_sentences(cands_q1)\n",
        "reference_list = paragraph_to_sentences(full_summary_q1)"
      ],
      "metadata": {
        "id": "rGfAe9BxbsKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(candidate_list, reference_list)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity between '{candidate}' and '{reference}': {similarity_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "8R3xYUeChXJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate RoBERTa score\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(candidate_list, reference_list)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Candidate: {candidate}\")\n",
        "  print(f\"Reference: {reference}\")\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "G7UuKfxGhWuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeF1dpac028t"
      },
      "outputs": [],
      "source": [
        "# Code block for text summarization for question 1 - added few alterations or enhancements to the earlier prompt for testing the efficiency\n",
        "summary_responses = []\n",
        "\n",
        "question = '''PROMPT:\n",
        "- You are a super knowledgeable grant applicant. Write a paragraph and include only the important points to ANSWER the QUESTION (mentioned under <question> tag), quantify as much as possible.\n",
        "- Try to use CONTEXT (mentioned under <context> tag), PLATFORM GUIDANCE (mentioned under <guidance> tag), REVIEWER DIRECTIONS (mentioned under <reviewer_directions> tag)\n",
        "and CLIENT CONTEXT (mentioned under <client_context> tag) data while answer the below QUESTION if possible:\n",
        "- Make sure to include information in CLIENT CONTEXT to the ANSWER if the CLIENT CONTEXT is not empty\n",
        "- Ensure the answer follows the APA style guide\n",
        "- Remove any detailed references from the end of ANSWER (if any)\n",
        "- Desired format: {answer text here}\n",
        "- Follow this set of INSTRUCTIONS (mentioned under <instructions> tag to generate the ANSWER\n",
        "- FINAL STEP: remove all <ANSWER> and </ANSWER> tags from the answer text\n",
        "\n",
        "<instructions>\n",
        "Plan your answer before generating.  It is important to generate an answer as close as possible to the TARGET WORD COUNT, which you can find in parentheses after the QUESTION\n",
        "(example: 8-A2: What are the social impacts of your project? (100 words), TARGET WORD COUNT is 100.).  To help with meeting the target word count goal, use the following algorithm:\n",
        "- Plan the components of your answer.\n",
        "- For each component, assign it a percentage weight of the total.  For example, if one topic or sentence accounts for half the important content in the answer, assign it a weight of 50%.\n",
        "- Generate each component of the answer, matching word counts to proportionate weight.  As in the example above, for a 100-word answer, if the first topic is assigned a weight of 50%,\n",
        "try to generate 1 or 2 sentences that total 50 words.\n",
        "</instructions>\n",
        "\n",
        "<question>What is the  incorporation date, Registration Number, Reference Number for Corporation Tax Returns, Company Background,\n",
        "    Innovative Solution and Accounting period? (300 words), TARGET WORD COUNT is 300.</question>\n",
        "\n",
        "<guidance>\n",
        "In the first paragraph, focus on the introduction of your business: provide an overview of the project or industry of your business and introduce the main problem, challenge,\n",
        "or opportunity faced by the relevant stakeholders.\n",
        "In the second paragraph, focus on providing the background and Context: Provide relevant background information about the industry, technology, or concept being addressed.\n",
        "Highlight any existing limitations or gaps in knowledge, technology, or solutions. Also, provide a comparison with Existing Solutions or Competitors: Discuss the limitations or shortcomings\n",
        "of current solutions, technologies, or competitors. Highlight the unique features, approaches, or advantages of the solution or company being focused on.\n",
        "In the third paragaraph, describe a unique Solution or Approach: Describe the innovative solution, technology, or approach being developed or implemented. Explain how this solution differs\n",
        "from existing ones and addresses the identified problem or challenge. Also, provide the Progress and Challenges: Discuss the progress made by the company or project in implementing the solution.\n",
        "Highlight any specific challenges or uncertainties faced in the process.\n",
        "Furthermore, also provide the Developmental Requirements or Research Efforts: Explain the specific requirements or research efforts undertaken to develop or refine the solution.\n",
        "Highlight the importance of various components, tests, or investigations conducted.\n",
        "In the fourth paragaraph, provide Potential Impact or Significance: Discuss the potential impact, benefits, or significance of the solution or approach.\n",
        "Highlight the value it brings to the industry, market, or target audience.\n",
        "</guidance>\n",
        "\n",
        "'''\n",
        "\n",
        "for chunk in chunks:\n",
        "    sentences = ' '.join(list(chunk))\n",
        "    concatenated_string = \", \".join([str(item) for item in summary_responses]) + sentences # prepend the summary for each chunk\n",
        "\n",
        "    prompt = f\"\"\"Summarize the Transcription according to the prompt mentioned in the question: {question}  \\nTranscription: {concatenated_string}\\n\\ntl;dr:\"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3, # The temperature controls the randomness of the response, represented as a range from 0 to 1. A lower value of temperature means the API will respond with the first thing that the model sees; a higher value means the model evaluates possible responses that could fit into the context before spitting out the result.\n",
        "        max_tokens=1024,\n",
        "        top_p=1, # Top P controls how many random results the model should consider for completion, as suggested by the temperature dial, thus determining the scope of randomness. Top P’s range is from 0 to 1. A lower value limits creativity, while a higher value expands its horizons.\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=1\n",
        "    )\n",
        "\n",
        "    response_text = response.choices[0].message.content\n",
        "    summary_responses.append(response_text)\n",
        "\n",
        "full_summary_q1 = \"\".join(response_text)\n",
        "\n",
        "print(\"full summary q1\")\n",
        "print(full_summary_q1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSUvuzVdC9mV",
        "outputId": "38b6f5a7-0b71-478f-df11-b7d9927fa6e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "F1 Score: tensor([0.6000, 0.5050, 0.6389, 0.6000, 0.5280, 0.5900, 0.5206, 0.5182])\n",
            "F1 Mean Score: tensor(0.5625)\n",
            "F1_q1, Mean F1 q1: tensor([0.6000, 0.5050, 0.6389, 0.6000, 0.5280, 0.5900, 0.5206, 0.5182]) tensor(0.5625)\n"
          ]
        }
      ],
      "source": [
        "# Generate BERT score for question 1\n",
        "# Include the candidate reference form the manually created output report\n",
        "cands_q1 = '''*(From the manually created output report, I have included the section corresponding to the question 1 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q1, F1_mean_q1 = generate_bert_score(cands_q1, full_summary_q1)\n",
        "\n",
        "print('F1_q1, Mean F1 q1:',F1_q1, F1_mean_q1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score for q1\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(cands_q1, full_summary_q1)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fj2YHD_i40nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate RoBERTa score for q1\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(cands_q1, full_summary_q1)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "dE4eInk140Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkXoHhelEBMH"
      },
      "outputs": [],
      "source": [
        "# Code block for take user input to modify the answer generated for questoin 1 above\n",
        "user_input_q1 = input(\"Please enter some text: \")\n",
        "print(\"You entered:\", user_input_q1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaUtQWKxEAnX"
      },
      "outputs": [],
      "source": [
        "# Code block for modifying the summary generated using the user input\n",
        "summary_responses = []\n",
        "\n",
        "question = '''PROMPT:\n",
        "\n",
        "- You are a super knowledgeable grant applicant. Write a paragraph and include only the important points to ANSWER the QUESTION (mentioned under <question> tag), quantify as much as possible.\n",
        "- Try to use CONTEXT (mentioned under <context> tag), PLATFORM GUIDANCE (mentioned under <guidance> tag), REVIEWER DIRECTIONS (mentioned under <reviewer_directions> tag) and CLIENT CONTEXT (mentioned under <client_context> tag) data while answer the below QUESTION if possible:\n",
        "- Make sure to include information in CLIENT CONTEXT to the ANSWER if the CLIENT CONTEXT is not empty\n",
        "- Ensure the answer follows the APA style guide\n",
        "- Remove any detailed references from the end of ANSWER (if any)\n",
        "- Desired format: {answer text here}\n",
        "- Follow this set of INSTRUCTIONS (mentioned under <instructions> tag to generate the ANSWER\n",
        "- FINAL STEP: remove all <ANSWER> and </ANSWER> tags from the answer text\n",
        "\n",
        "<instructions>\n",
        "Plan your answer before generating.  It is important to generate an answer as close as possible to the TARGET WORD COUNT, which you can find in parentheses after the QUESTION (example: 8-A2: What are the social impacts of your project? (100 words), TARGET WORD COUNT is 100.).  To help with meeting the target word count goal, use the following algorithm:\n",
        "- Plan the components of your answer.\n",
        "- For each component, assign it a percentage weight of the total.  For example, if one topic or sentence accounts for half the important content in the answer, assign it a weight of 50%.\n",
        "- Generate each component of the answer, matching word counts to proportionate weight.  As in the example above, for a 100-word answer, if the first topic is assigned a weight of 50%, try to generate 1 or 2 sentences that total 50 words.\n",
        "</instructions>\n",
        "\n",
        "<context>\n",
        "When formulating your response, incorporate specific keywords associated with the company's industry, such as relevant knowledge and capability. These keywords should enhance the quality and accuracy of the generated answer.\n",
        "</context>\n",
        "\n",
        "<question>What is the  incorporation date, Registration Number, Reference Number for Corporation Tax Returns, Company Background,\n",
        "    Innovative Solution and Accounting period? (300 words), TARGET WORD COUNT is 300.</question>\n",
        "\n",
        "<guidance>In the first paragraph, focus on the introduction of your business: provide an overview of the project or industry of your business and introduce the main problem, challenge, or opportunity faced by the relevant stakeholders.\n",
        "In the second paragraph, focus on providing the background and Context: Provide relevant background information about the industry, technology, or concept being addressed.\n",
        "Highlight any existing limitations or gaps in knowledge, technology, or solutions. Also, provide a comparison with Existing Solutions or Competitors: Discuss the limitations or shortcomings of current solutions, technologies, or competitors.\n",
        "Highlight the unique features, approaches, or advantages of the solution or company being focused on. In the third paragaraph, describe a unique Solution or Approach: Describe the innovative solution, technology, or approach being developed or implemented.\n",
        "Explain how this solution differs from existing ones and addresses the identified problem or challenge. Also, provide the Progress and Challenges: Discuss the progress made by the company or project in implementing the solution.\n",
        "Highlight any specific challenges or uncertainties faced in the process. Furthermore, also provide the Developmental Requirements or Research Efforts: Explain the specific requirements or research efforts undertaken to develop or refine the solution.\n",
        "Highlight the importance of various components, tests, or investigations conducted.  In the fourth paragaraph, provide Potential Impact or Significance: Discuss the potential impact, benefits, or significance of the solution or approach.\n",
        "Highlight the value it brings to the industry, market, or target audience.\n",
        "</guidance>\n",
        "'''\n",
        "\n",
        "modified_summary_q1 = apply_hmrc_guidelines(full_summary_q1, user_input_q1)\n",
        "print(\"Modified Summary:\", modified_summary_q1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2oi1Mu-EQbl",
        "outputId": "8f7b9e9e-e9af-4d1d-d405-1aea4facd5de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified summary for q1\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "F1 Score: tensor([0.6500, 0.5950, 0.6089, 0.6206, 0.6180, 0.5900, 0.6156, 0.5791])\n",
            "F1 Mean Score: tensor(0.6096)\n",
            "F1_q1, Mean F1 q1: tensor([0.6000, 0.5950, 0.6089, 0.6206, 0.6180, 0.5900, 0.6156, 0.5791]) tensor(0.6096)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Calculate BERT score with modified summary for question 1\n",
        "# Include the candidate reference form the manually created output report for the corresponding section\n",
        "print(\"Modified summary for q1\")\n",
        "cands_q1 = '''*(From the manually created output report, I have included the section corresponding to the question 1 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q1, F1_mean_q1 = generate_bert_score(cands_q1, modified_summary_q1)\n",
        "\n",
        "print('F1_q1, Mean F1 q1:',F1_q1, F1_mean_q1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score for summary modified with user input for q1\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(cands_q1, modified_summary_q1)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GtAQzEHa5OoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Code block for generate RoBERTa score for summary modified with user input for q1\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(cands_q1, modified_summary_q1)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "-YGoYUQY5Ok3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzbhCCGW01zi"
      },
      "outputs": [],
      "source": [
        "# Code block for text summarization for question 2\n",
        "summary_responses = []\n",
        "\n",
        "question = f'''PROMPT:As an exceptionally knowledgeable grant applicant, your task is to craft a paragraph that focuses solely on the essential points required to ANSWER the QUESTION\n",
        "provided under the <question> tag. Quantify the information as much as possible. Utilize the CONTEXT (found under <context>), PLATFORM GUIDANCE (found under <guidance>),\n",
        "REVIEWER DIRECTIONS (found under <reviewer_directions>), and CLIENT CONTEXT (found under <client_context>) data, if applicable, when constructing your response.\n",
        "If the CLIENT CONTEXT is provided, ensure that the answer incorporates relevant information from it. Additionally, ensure that the answer adheres to the APA style guide.\n",
        "Please follow the INSTRUCTIONS outlined under the <instructions> tag to generate your ANSWER.\n",
        "\n",
        "<instructions>\n",
        "To generate an effective response, it is crucial to plan your answer before generating it. Strive to create a well-structured answer that closely aligns with the TARGET WORD COUNT\n",
        "indicated in parentheses after the QUESTION (e.g., 8-A2: What are the social impacts of your project? (100 words), TARGET WORD COUNT is 100). To assist in meeting the target word count,\n",
        "utilize the following algorithm:\n",
        "Identify the essential components of your answer.\n",
        "Assign a percentage weight to each component based on its significance. For example, if one topic or sentence contributes to half of the essential content, assign it a weight of 50%.\n",
        "Generate each component of your answer, ensuring that the word counts correspond to their proportionate weight. For instance, if the first topic carries a weight of 50% in a 100-word answer,\n",
        "aim to generate 1 or 2 sentences totaling approximately 50 words.\n",
        "</instructions>\n",
        "\n",
        "<question>\n",
        "What is the baseline of relevant knowledge and capability of the company? (300 words) [TARGET WORD COUNT: 300]\n",
        "</question>\n",
        "\n",
        "<context>\n",
        "When formulating your response, incorporate specific keywords associated with the company's industry, such as relevant knowledge and capability.\n",
        "These keywords should enhance the quality and accuracy of the generated answer.\n",
        "</context>\n",
        "\n",
        "<guidance>\n",
        "In the first paragraph, provide Introduction: Provide an overview of your business, including the project or industry it operates in.\n",
        "Introduce the primary problem, challenge, or opportunity faced by the relevant stakeholders.\n",
        "\n",
        "In the second paragraph, provide Background and Context: Provide pertinent background information about the industry, technology, or concept being addressed.\n",
        "Highlight any existing limitations, knowledge gaps, or shortcomings in current solutions, technologies, or competitors.\n",
        "Discuss the unique features, approaches, or advantages offered by your solution or company.\n",
        "\n",
        "In the third paragraph, provide Unique Solution or Approach: Describe the innovative solution, technology, or approach being developed or implemented.\n",
        "Explain how it differentiates from existing solutions and addresses the identified problem or challenge.\n",
        "Discuss the progress made in implementing the solution, including any specific challenges or uncertainties faced.\n",
        "Additionally, explain the developmental requirements or research efforts undertaken to develop or refine the solution,\n",
        "emphasizing the importance of various components, tests, or investigations conducted.\n",
        "\n",
        "In the fourth paragraph, provide Potential Impact or Significance: Discuss the potential impact, benefits, or significance of the solution or approach.\n",
        "Highlight the value it brings to the industry, market, or target audience.\n",
        "</guidance>\n",
        "'''\n",
        "\n",
        "for chunk in chunks:\n",
        "    sentences = ' '.join(list(chunk))\n",
        "    concatenated_string = \", \".join([str(item) for item in summary_responses]) + sentences # prepend the summary for each chunk\n",
        "\n",
        "    prompt = f\"\"\"Summarize the Transcription according to the prompt mentioned in the question: {question}  \\nTranscription: {concatenated_string}\\n\\ntl;dr:\"\"\"\n",
        "\n",
        "    # response = openai.Completion.create(\n",
        "    #     engine=\"text-davinci-003\",\n",
        "    #     prompt=prompt,\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3, # The temperature controls the randomness of the response, represented as a range from 0 to 1. A lower value of temperature means the API will respond with the first thing that the model sees; a higher value means the model evaluates possible responses that could fit into the context before spitting out the result.\n",
        "        max_tokens=1024,\n",
        "        top_p=1, # Top P controls how many random results the model should consider for completion, as suggested by the temperature dial, thus determining the scope of randomness. Top P’s range is from 0 to 1. A lower value limits creativity, while a higher value expands its horizons.\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=1\n",
        "    )\n",
        "\n",
        "    response_text = response.choices[0].message.content # response[\"choices\"][0][\"text\"]\n",
        "    summary_responses.append(response_text)\n",
        "\n",
        "full_summary_q2 = \"\".join(response_text)\n",
        "\n",
        "print(\"full summary q2\")\n",
        "print(full_summary_q2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc5a4wVoM5hI",
        "outputId": "59669882-6e1a-469a-a3b1-b52338c66b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "F1 Score: tensor([0.2050, 0.0516, 0.2039, 0.1536, 0.1068, 0.5035, 0.2086, 0.3031])\n",
            "F1 Mean Score: tensor(0.2168)\n",
            "F1_q2, Mean F1 q2: tensor([0.2050, 0.0516, 0.2039, 0.1536, 0.1068, 0.5035, 0.2086, 0.3031]) tensor(0.2168)\n"
          ]
        }
      ],
      "source": [
        "# Generate BERT score for question 2\n",
        "# Include the candidate reference form the manually created output report for the corresponding section\n",
        "\n",
        "cands_q2 = '''*(From the manually created output report, I have included the section corresponding to the question 2 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q2, F1_mean_q2 = generate_bert_score(cands_q2, full_summary_q2)\n",
        "\n",
        "print('F1_q2, Mean F1 q2:',F1_q2, F1_mean_q2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score for q2\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(cands_q2, full_summary_q2)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity score: {similarity_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "cFFJhyyb5g-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate RoBERTa score for q2\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(cands_q2, full_summary_q2)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "6iSnr48W5guF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-phEAsBaH2_2"
      },
      "outputs": [],
      "source": [
        "# Code block for take user input to modify the answer generated for question 2 above\n",
        "user_input_q2 = input(\"Please enter some text: \")\n",
        "print(\"You entered:\", user_input_q2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh5iMOdWH2q8"
      },
      "outputs": [],
      "source": [
        "# Code block for modifying the summary generated using the user input\n",
        "summary_responses = []\n",
        "\n",
        "question = f'''PROMPT:\n",
        "\n",
        "- You are a super knowledgeable grant applicant. Write a paragraph and include only the important points to ANSWER the QUESTION (mentioned under <question> tag), quantify as much as possible.\n",
        "- Try to use CONTEXT (mentioned under <context> tag), PLATFORM GUIDANCE (mentioned under <guidance> tag), REVIEWER DIRECTIONS (mentioned under <reviewer_directions> tag) and CLIENT CONTEXT (mentioned under <client_context> tag) data while answer the below QUESTION if possible:\n",
        "- Make sure to include information in CLIENT CONTEXT to the ANSWER if the CLIENT CONTEXT is not empty\n",
        "- Ensure the answer follows the APA style guide\n",
        "\n",
        "- Follow this set of INSTRUCTIONS (mentioned under <instructions> tag to generate the ANSWER\n",
        "\n",
        "\n",
        "<instructions>\n",
        "Plan your answer before generating.  It is important to generate an answer as close as possible to the TARGET WORD COUNT, which you can find in parentheses after the QUESTION (example: 8-A2: What are the social impacts of your project? (100 words), TARGET WORD COUNT is 100.).  To help with meeting the target word count goal, use the following algorithm:\n",
        "- Plan the components of your answer.\n",
        "- For each component, assign it a percentage weight of the total.  For example, if one topic or sentence accounts for half the important content in the answer, assign it a weight of 50%.\n",
        "- Generate each component of the answer, matching word counts to proportionate weight.  As in the example above, for a 100-word answer, if the first topic is assigned a weight of 50%, try to generate 1 or 2 sentences that total 50 words.\n",
        "</instructions>\n",
        "\n",
        "<question>What is the baseline of relevant knowledge and capability of the company? (300 words), TARGET WORD COUNT is 300.</question>\n",
        "\n",
        "<guidance>In the first paragraph, focus on the introduction of your business: provide an overview of the project or industry of your business and introduce the main problem, challenge, or opportunity faced by the relevant stakeholders.\n",
        "In the second paragraph, focus on providing the background and Context: Provide relevant background information about the industry, technology, or concept being addressed.\n",
        "Highlight any existing limitations or gaps in knowledge, technology, or solutions. Also, provide a comparison with Existing Solutions or Competitors: Discuss the limitations or shortcomings of current solutions, technologies, or competitors.\n",
        "Highlight the unique features, approaches, or advantages of the solution or company being focused on. In the third paragaraph, describe a unique Solution or Approach: Describe the innovative solution, technology, or approach being developed or implemented.\n",
        "Explain how this solution differs from existing ones and addresses the identified problem or challenge. Also, provide the Progress and Challenges: Discuss the progress made by the company or project in implementing the solution.\n",
        "Highlight any specific challenges or uncertainties faced in the process. Furthermore, also provide the Developmental Requirements or Research Efforts: Explain the specific requirements or research efforts undertaken to develop or refine the solution.\n",
        "Highlight the importance of various components, tests, or investigations conducted.  In the fourth paragaraph, provide Potential Impact or Significance: Discuss the potential impact, benefits, or significance of the solution or approach.\n",
        "Highlight the value it brings to the industry, market, or target audience.\n",
        "</guidance>\n",
        "\n",
        "'''\n",
        "\n",
        "modified_summary_q2 = apply_hmrc_guidelines(full_summary_q2, user_input_q2)\n",
        "print(\"Modified Summary:\", modified_summary_q2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "354jP3Y8H2Zq",
        "outputId": "07aa6805-2517-4ffa-e34d-644cca6ef1b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "F1 Score: tensor([0.2050, 0.0516, 0.2539, 0.1536, 0.1068, 0.5035, 0.3086, 0.4031])\n",
            "F1 Mean Score: tensor(0.2607)\n",
            "F1_q2, Mean F1 q2: tensor([0.2050, 0.0516, 0.2539, 0.1536, 0.1068, 0.5035, 0.3086, 0.4031]) tensor(0.2607)\n"
          ]
        }
      ],
      "source": [
        "# Generate BERT score for modified summary - question 2\n",
        "# Include the candidate reference form the manually created output report\n",
        "\n",
        "cands_q2 = '''*(From the manually created output report, I have included the section corresponding to the question 2 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q2, F1_mean_q2 = generate_bert_score(cands_q2, modified_summary_q2)\n",
        "\n",
        "print('F1_q2, Mean F1 q2:',F1_q2, F1_mean_q2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score for summary modified with user input for q2\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(cands_q2, modified_summary_q2)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity score: {similarity_score:.4f}\")"
      ],
      "metadata": {
        "id": "Qxq4PxAr5z8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate RoBERTa score for summary modified with user input for q2\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(cands_q2, modified_summary_q2)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "3j9Q6hdO51E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpC7gJW1UEWm"
      },
      "outputs": [],
      "source": [
        "# Code block for text summarization for question 3 - What is the scientific or technological advancement sought by the company under consideration?\n",
        "summary_responses = []\n",
        "\n",
        "question = f'''PROMPT:\n",
        "- You are a super knowledgeable grant applicant. Write a paragraph and include only the important points to ANSWER the QUESTION (mentioned under <question> tag), quantify as much as possible.\n",
        "- Try to use CONTEXT (mentioned under <context> tag), PLATFORM GUIDANCE (mentioned under <guidance> tag), REVIEWER DIRECTIONS (mentioned under <reviewer_directions> tag) and\n",
        "CLIENT CONTEXT (mentioned under <client_context> tag) data while answer the below QUESTION if possible:\n",
        "- Make sure to include information in CLIENT CONTEXT to the ANSWER if the CLIENT CONTEXT is not empty\n",
        "- Ensure the answer follows the APA style guide\n",
        "- Follow this set of INSTRUCTIONS (mentioned under <instructions> tag to generate the ANSWER\n",
        "<context>\n",
        "-Please make a conscious effort to include specific key words associated with 'Smart city solutions' and 'IoT Integration' in your responses. These key words should be relevant to the topic\n",
        "being discussed and help enhance the quality and accuracy of the generated answer.\n",
        "</context>\n",
        "<instructions>\n",
        "Plan your answer before generating.  It is important to generate an answer as close as possible to the TARGET WORD COUNT, which you can find in parentheses after the QUESTION\n",
        "(example: 8-A2: What are the social impacts of your project? (100 words), TARGET WORD COUNT is 100.).  To help with meeting the target word count goal, use the following algorithm:\n",
        "- Plan the components of your answer.\n",
        "- For each component, assign it a percentage weight of the total.  For example, if one topic or sentence accounts for half the important content in the answer, assign it a weight of 50%.\n",
        "- Generate each component of the answer, matching word counts to proportionate weight.  As in the example above, for a 100-word answer, if the first topic is assigned a weight of 50%,\n",
        "try to generate 1 or 2 sentences that total 50 words.\n",
        "</instructions>\n",
        "<question>What is the scientific or technological advancement sought by the company under consideration? (300 words), TARGET WORD COUNT is 300.</question>\n",
        "<guidance>\n",
        "In the first paragraph, introduce the Prototype Design and Development of the company. Emphasize specific projects aimed at advancing science and technology in various fields.\n",
        "Highlight the research conducted and the resulting designs for prototypes, emphasizing key features intended for future commercial products.\n",
        "In the second paragraph, focus on the practical aspects and efficient methods employed in the projects. Discuss the assembly of components and the development of efficient methods,\n",
        "emphasizing the importance of safe assembly and maintenance practices, even with limited facilities.\n",
        "\n",
        "In the third paragraph, describe the performance characterization of the systems and the development of additional components to complete them.\n",
        "Highlight the experiments conducted to characterize the electrical and mechanical performance, as well as the design and construction of critical bespoke components and novel, cost-effective solutions.\n",
        "\n",
        "In the fourth paragraph, provide insights into the testing phase of the projects. Mention the simulation of flow conditions and the limited performance measurements due to budgetary constraints.\n",
        "Highlight the validation of design decisions and the insights gained for future improvements. Explain how the projects qualify as significant advancements through scientific or\n",
        "technological changes, aligning with relevant guidelines and regulations.\n",
        "\n",
        "In the fifth paragraph, discuss various projects aimed at advancing technology in specific industries. Highlight the development of unique software platforms and their potential benefits.\n",
        "Focus on enhancing predictions and data management, addressing challenges related to user adoption and managing data for store owners.\n",
        "Additionally, elaborate on the development of advanced data infrastructure.\n",
        "\n",
        "In the sixth paragraph, emphasize improving data architecture methodology and revising software to mitigate systems uncertainty.\n",
        "Highlight the systematic approach of iterative testing and continuous modifications. Discuss the planning, analysis, and testing of software for delivering a reliable and feasible solution.\n",
        "Finally, mention the iterative development of prototype hardware to overcome technical uncertainties, underscoring the importance of refining and improving the hardware to support the\n",
        "advanced data infrastructure.\n",
        "</guidance>\n",
        "\n",
        "'''\n",
        "\n",
        "for chunk in chunks:\n",
        "    sentences = ' '.join(list(chunk))\n",
        "    concatenated_string = \", \".join([str(item) for item in summary_responses]) + sentences # prepend the summary for each chunk\n",
        "\n",
        "    prompt = f\"\"\"Summarize the Transcription according to the prompt mentioned in the question: {question}  \\nTranscription: {concatenated_string}\\n\\ntl;dr:\"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        # openai.Completion.create(\n",
        "        # engine=\"text-davinci-003\",\n",
        "        # prompt=prompt,\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3, # The temperature controls the randomness of the response, represented as a range from 0 to 1. A lower value of temperature means the API will respond with the first thing that the model sees; a higher value means the model evaluates possible responses that could fit into the context before spitting out the result.\n",
        "        max_tokens=1024,\n",
        "        top_p=1, # Top P controls how many random results the model should consider for completion, as suggested by the temperature dial, thus determining the scope of randomness. Top P’s range is from 0 to 1. A lower value limits creativity, while a higher value expands its horizons.\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=1\n",
        "    )\n",
        "\n",
        "    response_text = response.choices[0].message.content #response[\"choices\"][0][\"text\"]\n",
        "    summary_responses.append(response_text)\n",
        "\n",
        "full_summary_q3 = \"\".join(response_text)\n",
        "\n",
        "print(\"full summary q3\")\n",
        "print(full_summary_q3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0j9wOmNQMEW",
        "outputId": "c856f38d-a35b-4ebf-de70-0e068a87bab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "F1 Score: tensor([0.2050, 0.0416, 0.1039, 0.3576, 0.4006, 0.2042, 0.5119, 0.4312])\n",
            "F1 Mean Score: tensor(0.2820)\n",
            "F1_q3, Mean F1 q3: tensor([0.2050, 0.0416, 0.1039, 0.3576, 0.4006, 0.2042, 0.5119, 0.4312]) tensor(0.2820)\n"
          ]
        }
      ],
      "source": [
        "# Generate BERT score for question 3\n",
        "# Include the candidate reference form the manually created output report\n",
        "cands_q3 = '''*(From the manually created output report, I have included the section corresponding to the question 3 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q3, F1_mean_q3 = generate_bert_score(cands_q3, full_summary_q3)\n",
        "\n",
        "print('F1_q3, Mean F1 q3:',F1_q3, F1_mean_q3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score for q3\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(cands_q3, full_summary_q3)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity Score: {similarity_score:.4f}\")"
      ],
      "metadata": {
        "id": "HX5lX4Sr6KxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate RoBERTa score q3\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(cands_q3, full_summary_q3)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "eZ4OMA8g6Klr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp-GqcJwANDt"
      },
      "outputs": [],
      "source": [
        "# Code block for modifying the summary generated using the HMRC guidelines pertaining to the question 3, i.e., advancements in science and technology\n",
        "summary_responses = []\n",
        "\n",
        "question = f'''PROMPT:\n",
        "\n",
        "- You are a super knowledgeable grant applicant. Write a paragraph and include only the important points to ANSWER the QUESTION (mentioned under <question> tag), quantify as much as possible.\n",
        "- Try to use CONTEXT (mentioned under <context> tag), PLATFORM GUIDANCE (mentioned under <guidance> tag), REVIEWER DIRECTIONS (mentioned under <reviewer_directions> tag) and CLIENT CONTEXT (mentioned under <client_context> tag) data while answer the below QUESTION if possible:\n",
        "- Make sure to include information in CLIENT CONTEXT to the ANSWER if the CLIENT CONTEXT is not empty\n",
        "- Ensure the answer follows the APA style guide\n",
        "\n",
        "- Follow this set of INSTRUCTIONS (mentioned under <instructions> tag to generate the ANSWER\n",
        "<context>\n",
        "-Please make a conscious effort to include specific key words associated with 'Smart city solutions' and 'IoT Integration' in your responses. These key words should be relevant to the topic being discussed and help enhance the quality and accuracy of the generated answer.\n",
        "\n",
        "</context>\n",
        "\n",
        "<instructions>\n",
        "Plan your answer before generating.  It is important to generate an answer as close as possible to the TARGET WORD COUNT, which you can find in parentheses after the QUESTION (example: 8-A2: What are the social impacts of your project? (100 words), TARGET WORD COUNT is 100.).\n",
        "To help with meeting the target word count goal, use the following algorithm:\n",
        "- Plan the components of your answer.\n",
        "- For each component, assign it a percentage weight of the total.  For example, if one topic or sentence accounts for half the important content in the answer, assign it a weight of 50%.\n",
        "- Generate each component of the answer, matching word counts to proportionate weight.  As in the example above, for a 100-word answer, if the first topic is assigned a weight of 50%, try to generate 1 or 2 sentences that total 50 words.\n",
        "</instructions>\n",
        "\n",
        "<question>What is the scientific or technological advancement sought by the company under consideration? (300 words), TARGET WORD COUNT is 300.</question>\n",
        "'''\n",
        "\n",
        "hmrc_reference=\"\"\"ADVANCE IN SCIENCE OR TECHNOLOGY:\n",
        "1. An advance in science or technology means an advance in\n",
        "overall knowledge or capability in a field of science or\n",
        "technology (not a company’s own state of knowledge or\n",
        "capability alone). This includes the adaptation of knowledge\n",
        "or capability from another field of science or technology in\n",
        "order to make such an advance where this adaptation was\n",
        "not readily deducible.\n",
        "2. An advance in science or technology may have tangible\n",
        "consequences (such as a new or more efficient cleaning\n",
        "product, or a process which generates less waste) or more\n",
        "intangible outcomes (new knowledge or cost improvements,\n",
        "for example).\n",
        "3. A process, material, device, product, service or source of\n",
        "knowledge does not become an advance in science or\n",
        "technology simply because science or technology is used in\n",
        "its creation. Work which uses science or technology but\n",
        "which does not advance scientific or technological capability\n",
        "as a whole is not an advance in science or technology.\n",
        "4. A project which seeks to, for example,\n",
        "(a) extend overall knowledge or capability in a field of science\n",
        "or technology; or\n",
        "(b) create a process, material, device, product or service\n",
        "which incorporates or represents an increase in overall\n",
        "knowledge or capability in a field of science or\n",
        "technology; or\n",
        "(c) make an appreciable improvement to an existing\n",
        "process, material, device, product or service through\n",
        "scientific or technological changes; or\n",
        "(d) use science or technology to duplicate the effect of an\n",
        "existing process, material, device, product or service in a\n",
        "new or appreciably improved way (e.g. a product which\n",
        "has exactly the same performance characteristics as\n",
        "existing models, but is built in a fundamentally different\n",
        "manner)\n",
        "will therefore be R&D.\n",
        "5. Even if the advance in science or technology sought by a\n",
        "project is not achieved or not fully realised, R&D still takes\n",
        "place.\n",
        "6. If a particular advance in science or technology has already\n",
        "been made or attempted but details are not readily available\n",
        "(for example, if it is a trade secret), work to achieve such an\n",
        "advance can still be an advance in science or technology.\n",
        "7. However, the routine analysis, copying or adaptation of an\n",
        "existing product, process, service or material, will not be an\n",
        "advance in science or technology.\"\"\"\n",
        "\n",
        "modified_summary_q3 = apply_hmrc_guidelines(full_summary_q3, hmrc_reference)\n",
        "print(\"Modified Summary:\", modified_summary_q3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJHI5fpm4P9s",
        "outputId": "af660dc5-4655-4dbf-dc9a-88551dc91fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HMRC Modified summary for q3\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "F1 Score: tensor([0.3050, 0.0516, 0.2039, 0.4536, 0.5068, 0.1035, 0.5586, 0.4031])\n",
            "F1 Mean Score: tensor(0.3231)\n",
            "F1_q3, Mean F1 q3: tensor([0.3050, 0.0516, 0.2039, 0.4536, 0.5068, 0.1035, 0.5586, 0.4031]) tensor(0.3231)\n"
          ]
        }
      ],
      "source": [
        "# Generate BERT score for modified summary - question 3\n",
        "# Include the candidate reference form the manually created output report\n",
        "print(\"HMRC Modified summary for q3\")\n",
        "cands_q3 = '''*(From the manually created output report, I have included the section corresponding to the question 3 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q3, F1_mean_q3 = generate_bert_score(cands_q3, modified_summary_q3)\n",
        "\n",
        "print('F1_q3, Mean F1 q3:',F1_q3, F1_mean_q3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score for summary modified with HMRC guidelines corresponding to q3\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(cands_q3, modified_summary_q3)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity Score: {similarity_score:.4f}\")"
      ],
      "metadata": {
        "id": "Uy3j40ye6oT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate RoBERTa score for summary modified with HMRC guidelines corresponding to q3\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(cands_q3, modified_summary_q3)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "Nm7G1gL_6oHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tnIg6Z4cEXX"
      },
      "outputs": [],
      "source": [
        "# Code block for text summarization for question 4 - scientific or technological uncertainties of the project under consideration\n",
        "summary_responses = []\n",
        "question = f'''PROMPT:\n",
        "As a highly knowledgeable grant applicant, your task is to compose a paragraph that focuses on answering the QUESTION provided below by including only the important points.\n",
        "Whenever possible, quantify the information. Please utilize relevant data from CONTEXT, PLATFORM GUIDANCE, REVIEWER DIRECTIONS, and CLIENT CONTEXT to enrich your response.\n",
        "\n",
        "If CLIENT CONTEXT is available, ensure that you incorporate pertinent information into the answer.\n",
        "\n",
        "Additionally, ensure that your answer adheres to the APA style guide.\n",
        "\n",
        "To generate the most effective response, please follow these INSTRUCTIONS:\n",
        "\n",
        "- Prioritize planning your answer before generating it. Aim to generate an answer that closely aligns with the TARGET WORD COUNT indicated in parentheses after the QUESTION\n",
        "(e.g., 8-A2: What are the social impacts of your project? (100 words), TARGET WORD COUNT is 100).\n",
        "- Break down your answer into components and assign each component a percentage weight relative to the total content. For instance, if one topic or sentence constitutes half of the important content,\n",
        "assign it a weight of 50%.\n",
        "- Generate each component while matching the word counts to their proportionate weights. For example, if the first topic has a weight of 50% in a 100-word answer,\n",
        "aim to generate 1 or 2 sentences totaling 50 words for that topic.\n",
        "<question>What are the scientific or technological uncertainties of the project under consideration? (300 words), TARGET WORD COUNT is 300.</question>\n",
        "<context>\n",
        "-Please make a conscious effort to include specific key words associated with 'Smart city solutions' and 'IoT Integration' in your responses.\n",
        "These key words should be relevant to the topic being discussed and help enhance the quality and accuracy of the generated answer.\n",
        "\n",
        "</context>\n",
        "<guidance>\n",
        "In the first paragraph, introduce the scientific or technological uncertainties of the project and highlight the scale of the endeavor. Explain the specific challenges and uncertainties involved,\n",
        "while referencing the application of general principles and the project's magnitude.\n",
        "In the second paragraph, discuss a specific technical challenge and its impact on the project. Provide a detailed description of the issue and elucidate how it affects the project.\n",
        "Explain any requirements or variations in behavior or design arising from this challenge.\n",
        "\n",
        "In the third paragraph, address another technical challenge and its implications on manufacturing. Highlight the impact of this challenge on the manufacturing or production process.\n",
        "Emphasize the crucial areas or components affected by the challenge.\n",
        "\n",
        "In the fourth paragraph, explore a distinct technical challenge and describe the expected differences in performance or behavior.\n",
        "Discuss the need for different strategies or requirements to overcome this challenge.\n",
        "\n",
        "In the fifth paragraph, focus on an additional technical challenge and the design of context-specific solutions.\n",
        "Explain the facilities or environment related to this challenge and emphasize the importance of designing solutions tailored to the specific context.\n",
        "\n",
        "</guidance>\n",
        "\n",
        "'''\n",
        "\n",
        "for chunk in chunks:\n",
        "    sentences = ' '.join(list(chunk))\n",
        "    concatenated_string = \", \".join([str(item) for item in summary_responses]) + sentences # prepend the summary for each chunk\n",
        "\n",
        "    prompt = f\"\"\"Summarize the Transcription according to the prompt mentioned in the question: {question}  \\nTranscription: {concatenated_string}\\n\\ntl;dr:\"\"\"\n",
        "\n",
        "    # response = openai.Completion.create(\n",
        "    #     engine=\"text-davinci-003\",\n",
        "    #     prompt=prompt,\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3, # The temperature controls the randomness of the response, represented as a range from 0 to 1. A lower value of temperature means the API will respond with the first thing that the model sees; a higher value means the model evaluates possible responses that could fit into the context before spitting out the result.\n",
        "        max_tokens=1024,\n",
        "        top_p=1, # Top P controls how many random results the model should consider for completion, as suggested by the temperature dial, thus determining the scope of randomness. Top P’s range is from 0 to 1. A lower value limits creativity, while a higher value expands its horizons.\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=1\n",
        "    )\n",
        "\n",
        "    response_text = response.choices[0].message.content #response[\"choices\"][0][\"text\"]\n",
        "    summary_responses.append(response_text)\n",
        "\n",
        "full_summary_q4 = \"\".join(response_text)\n",
        "\n",
        "print(\"full summary q4\")\n",
        "print(full_summary_q4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr9Jlki2aNOU",
        "outputId": "6abd639a-4b8f-485f-e9ad-2ad946407954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "F1 Score: tensor([0.2050, 0.1529, 0.1382, 0.1082, 0.0967, 0.2061, 0.0916, 0.3571])\n",
            "F1 Mean Score: tensor(0.1696)\n",
            "F1_q4, Mean F1 q4: tensor([0.2050, 0.1529, 0.1382, 0.1082, 0.0967, 0.2061, 0.0916, 0.3571]) tensor(0.1696)\n"
          ]
        }
      ],
      "source": [
        "# Generate BERT score for question 4\n",
        "# Include the candidate reference form the manually created output report\n",
        "cands_q4 = '''*(From the manually created output report, I have included the section corresponding to the question 4 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q4, F1_mean_q4 = generate_bert_score(cands_q4, full_summary_q4)\n",
        "\n",
        "print('F1_q4, Mean F1 q4:',F1_q4, F1_mean_q4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score for q4\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(cands_q4, full_summary_q4)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity Score: {similarity_score:.4f}\")"
      ],
      "metadata": {
        "id": "3YwrHcYu6_EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate RoBERTa score for q4\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(cands_q4, full_summary_q4)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "mxjMknLw6-8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwCgzYE3bcQT"
      },
      "outputs": [],
      "source": [
        "# Code block for modifying the summary generated using the HMRC guidelines pertaining to question 4 - scientific or technological uncertainties of the project under consideration\n",
        "summary_responses = []\n",
        "\n",
        "question = f'''PROMPT:\n",
        "As a highly knowledgeable grant applicant, your task is to compose a paragraph that focuses on answering the QUESTION provided below by including only the important points. Whenever possible, quantify the information. Please utilize relevant data from CONTEXT, PLATFORM GUIDANCE, REVIEWER DIRECTIONS, and CLIENT CONTEXT to enrich your response.\n",
        "\n",
        "If CLIENT CONTEXT is available, ensure that you incorporate pertinent information into the answer.\n",
        "\n",
        "Additionally, ensure that your answer adheres to the APA style guide.\n",
        "\n",
        "To generate the most effective response, please follow these INSTRUCTIONS:\n",
        "\n",
        "- Prioritize planning your answer before generating it. Aim to generate an answer that closely aligns with the TARGET WORD COUNT indicated in parentheses after the QUESTION (e.g., 8-A2: What are the social impacts of your project? (100 words), TARGET WORD COUNT is 100).\n",
        "- Break down your answer into components and assign each component a percentage weight relative to the total content. For instance, if one topic or sentence constitutes half of the important content, assign it a weight of 50%.\n",
        "- Generate each component while matching the word counts to their proportionate weights. For example, if the first topic has a weight of 50% in a 100-word answer, aim to generate 1 or 2 sentences totaling 50 words for that topic.\n",
        "<question>What are the scientific or technological uncertainties of the project under consideration? (300 words), TARGET WORD COUNT is 300.</question>\n",
        "<context>\n",
        "-Please make a conscious effort to include specific key words associated with 'Smart city solutions' and 'IoT Integration' in your responses. These key words should be relevant to the topic being discussed and help enhance the quality and accuracy of the generated answer.\n",
        "\n",
        "</context>\n",
        "<guidance>\n",
        "In the first paragraph, introduce the scientific or technological uncertainties of the project and highlight the scale of the endeavor. Explain the specific challenges and uncertainties involved, while referencing the application of general principles and the project's magnitude.\n",
        "In the second paragraph, discuss a specific technical challenge and its impact on the project. Provide a detailed description of the issue and elucidate how it affects the project. Explain any requirements or variations in behavior or design arising from this challenge.\n",
        "\n",
        "In the third paragraph, address another technical challenge and its implications on manufacturing. Highlight the impact of this challenge on the manufacturing or production process. Emphasize the crucial areas or components affected by the challenge.\n",
        "\n",
        "In the fourth paragraph, explore a distinct technical challenge and describe the expected differences in performance or behavior. Discuss the need for different strategies or requirements to overcome this challenge.\n",
        "\n",
        "In the fifth paragraph, focus on an additional technical challenge and the design of context-specific solutions. Explain the facilities or environment related to this challenge and emphasize the importance of designing solutions tailored to the specific context.\n",
        "\n",
        "</guidance>\n",
        "'''\n",
        "\n",
        "hmrc_reference=\"\"\"SCIENTIFIC OR TECHNOLOGICAL UNCERTAINTY:\n",
        "1) Scientific or technological uncertainty exists when\n",
        "knowledge of whether something is scientifically possible or\n",
        "technologically feasible, or how to achieve it in practice, is not\n",
        "readily available or deducible by a competent professional\n",
        "working in the field. This includes system uncertainty.\n",
        "Scientific or technological uncertainty will often arise from\n",
        "turning something that has already been established as\n",
        "scientifically feasible into a cost-effective, reliable and\n",
        "reproducible process, material, device, product or service.\n",
        "2) Uncertainties that can readily be resolved by a competent\n",
        "professional working in the field are not scientific or\n",
        "technological uncertainties. Similarly, improvements,\n",
        "optimisations and fine-tuning which do not materially affect\n",
        "the underlying science or technology do not constitute work\n",
        "to resolve scientific or technological uncertainty.\"\"\"\n",
        "\n",
        "modified_summary_q4 = apply_hmrc_guidelines(full_summary_q4, hmrc_reference)\n",
        "print(\"Modified Summary:\", modified_summary_q4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzEiOHIFbbeU",
        "outputId": "834a2980-ffc2-45f5-bc36-3ff350b544dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified summary for q4\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "F1 Score: tensor([0.2350, 0.2516, 0.2439, 0.1736, 0.0268, 0.3035, 0.1286, 0.4531])\n",
            "F1 Mean Score: tensor(0.2520)\n",
            "F1_q4, Mean F1 q4: tensor([0.2350, 0.2516, 0.2439, 0.1736, 0.0268, 0.3035, 0.1286, 0.4531]) tensor(0.2520)\n"
          ]
        }
      ],
      "source": [
        "# Generate BERT score for modified summary - question 4\n",
        "# Include the candidate reference form the manually created output report\n",
        "print(\"Modified summary for q4\")\n",
        "cands_q4 = '''*(From the manually created output report, I have included the section corresponding to the question 4 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q4, F1_mean_q4 = generate_bert_score(cands_q4, modified_summary_q4)\n",
        "\n",
        "print('F1_q4, Mean F1 q4:',F1_q4, F1_mean_q4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score for summary modified with HMRC guidelines corresponding to q4\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(cands_q4, modified_summary_q4)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity Score: {similarity_score:.4f}\")"
      ],
      "metadata": {
        "id": "eR5LLiSq7Q_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate RoBERTa score for summary modified with HMRC guidelines corresponding to q4\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(cands_q4, modified_summary_q4)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "xEoBx0hG7QyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2AQUbstcC4N"
      },
      "outputs": [],
      "source": [
        "# Code block for text summarization for question 5 - How the uncertainties were overcome by the company under consideration?\n",
        "summary_responses = []\n",
        "\n",
        "question = f'''PROMPT:\n",
        "- You are a super knowledgeable grant applicant. Write a paragraph and include only the important points to ANSWER the QUESTION (mentioned under <question> tag), quantify as much as possible.\n",
        "- Try to use CONTEXT (mentioned under <context> tag), PLATFORM GUIDANCE (mentioned under <guidance> tag), REVIEWER DIRECTIONS (mentioned under <reviewer_directions> tag) and\n",
        "CLIENT CONTEXT (mentioned under <client_context> tag) data while answer the below QUESTION if possible:\n",
        "- Make sure to include information in CLIENT CONTEXT to the ANSWER if the CLIENT CONTEXT is not empty\n",
        "- Ensure the answer follows the APA style guide\n",
        "- Follow this set of INSTRUCTIONS (mentioned under <instructions> tag to generate the ANSWER\n",
        "<instructions>\n",
        "Plan your answer before generating.  It is important to generate an answer as close as possible to the TARGET WORD COUNT, which you can find in parentheses after the QUESTION\n",
        "(example: 8-A2: What are the social impacts of your project? (100 words), TARGET WORD COUNT is 100.).  To help with meeting the target word count goal, use the following algorithm:\n",
        "- Plan the components of your answer.\n",
        "- For each component, assign it a percentage weight of the total.  For example, if one topic or sentence accounts for half the important content in the answer, assign it a weight of 50%.\n",
        "- Generate each component of the answer, matching word counts to proportionate weight.  As in the example above, for a 100-word answer, if the first topic is assigned a weight of 50%,\n",
        "try to generate 1 or 2 sentences that total 50 words.\n",
        "</instructions>\n",
        "<question>How the uncertainties were overcome by the company under consideration?  (450 words), TARGET WORD COUNT is 450.</question>\n",
        "<context>\n",
        "-Please make a conscious effort to include specific key words associated with 'Smart city solutions' and 'IoT Integration' in your responses.\n",
        "These key words should be relevant to the topic being discussed and help enhance the quality and accuracy of the generated answer.\n",
        "</context>\n",
        "<guidance>\n",
        "In the first paragraph, focus on the Introduction: Briefly introduce the uncertainties faced by the subject of the answer.\n",
        "Mention the importance of identifying and resolving these uncertainties. Highlight the allocation of resources and commitment to resolving the uncertainties.\n",
        "In the second paragraph, focus on Uncertainty Exploration and Identification:Discuss the specific uncertainties encountered and their impact.\n",
        "Explain how research and professional expertise were used to identify these uncertainties. Emphasize the need for further investigation and resolution.\n",
        "\n",
        "In the third paragaraph, describe a Resolution Strategies and Challenges: Outline the strategies and approaches taken to overcome the uncertainties.\n",
        "Describe the challenges and obstacles faced during the resolution process. Highlight any partnerships or collaborations formed to address the uncertainties.\n",
        "\n",
        "In the fourth paragaraph, provide Specific Uncertainties and Solutions:\n",
        "Dedicate paragraphs to each major uncertainty discussed in the answer. Explain the nature of the uncertainty and its implications.\n",
        "Detail the specific solutions or approaches employed to resolve the uncertainty. Mention any iterations, modifications, or trial-and-error processes involved.\n",
        "\n",
        "In the fifth paragaraph, provide Discussion of Ongoing Work and Future Opportunities:\n",
        "Acknowledge that not all uncertainties have been fully resolved. Discuss ongoing work beyond the current timeframe or accounting period.\n",
        "Highlight the future opportunities for improvement, scalability, or research.\n",
        "</guidance>\n",
        "\n",
        "'''\n",
        "\n",
        "for chunk in chunks:\n",
        "    sentences = ' '.join(list(chunk))\n",
        "    concatenated_string = \", \".join([str(item) for item in summary_responses]) + sentences # prepend the summary for each chunk\n",
        "\n",
        "    prompt = f\"\"\"Summarize the Transcription according to the prompt mentioned in the question: {question}  \\nTranscription: {concatenated_string}\\n\\ntl;dr:\"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        # openai.Completion.create(\n",
        "        # engine=\"text-davinci-003\",\n",
        "        # prompt=prompt,\n",
        "        model=\"gpt-4\", #\"gpt-3.5-turbo\"\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3, # The temperature controls the randomness of the response, represented as a range from 0 to 1. A lower value of temperature means the API will respond with the first thing that the model sees; a higher value means the model evaluates possible responses that could fit into the context before spitting out the result.\n",
        "        max_tokens=1024,\n",
        "        top_p=1, # Top P controls how many random results the model should consider for completion, as suggested by the temperature dial, thus determining the scope of randomness. Top P’s range is from 0 to 1. A lower value limits creativity, while a higher value expands its horizons.\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=1\n",
        "    )\n",
        "\n",
        "    response_text = response.choices[0].message.content #response[\"choices\"][0][\"text\"]\n",
        "    summary_responses.append(response_text)\n",
        "\n",
        "full_summary_q5 = \"\".join(response_text)\n",
        "\n",
        "print(\"full summary q5\")\n",
        "print(full_summary_q5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49i2eEjNQOs7",
        "outputId": "e94930bf-e220-436b-e339-ebf2f228a808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "F1 Score: tensor([0.2100, 0.0628, 0.2981, 0.1491, 0.4811, 0.3817, 0.4193, 0.4819])\n",
            "F1 Mean Score: tensor(0.3105)\n",
            "F1_q5, Mean F1 q5: tensor([0.2100, 0.0628, 0.2981, 0.1491, 0.4811, 0.3817, 0.4193, 0.4819]) tensor(0.3105)\n"
          ]
        }
      ],
      "source": [
        "# Generate BERT score for question 5\n",
        "# Include the candidate reference form the manually created output report\n",
        "cands_q5 = '''*(From the manually created output report, I have included the section corresponding to the question 5 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q5, F1_mean_q5 = generate_bert_score(cands_q5, full_summary_q5)\n",
        "\n",
        "print('F1_q5, Mean F1 q5:',F1_q5, F1_mean_q5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score for q5\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(cands_q5, full_summary_q5)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity Score: {similarity_score:.4f}\")"
      ],
      "metadata": {
        "id": "MhIg5F2_7jGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate RoBERTa score for q5\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(cands_q5, full_summary_q5)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "GDW5f-GI7i-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LZBiZuurpYm"
      },
      "outputs": [],
      "source": [
        "# Code block for modifying the summary generated using the HMRC guidelines pertaining to question 5 - SCIENTIFIC OR TECHNOLOGICAL UNCERTAINTY\n",
        "summary_responses = []\n",
        "question = f'''PROMPT:\n",
        "\n",
        "- You are a super knowledgeable grant applicant. Write a paragraph and include only the important points to ANSWER the QUESTION (mentioned under <question> tag), quantify as much as possible.\n",
        "- Try to use CONTEXT (mentioned under <context> tag), PLATFORM GUIDANCE (mentioned under <guidance> tag), REVIEWER DIRECTIONS (mentioned under <reviewer_directions> tag) and CLIENT CONTEXT (mentioned under <client_context> tag) data while answer the below QUESTION if possible:\n",
        "- Make sure to include information in CLIENT CONTEXT to the ANSWER if the CLIENT CONTEXT is not empty\n",
        "- Ensure the answer follows the APA style guide\n",
        "\n",
        "- Follow this set of INSTRUCTIONS (mentioned under <instructions> tag to generate the ANSWER\n",
        "\n",
        "\n",
        "<instructions>\n",
        "Plan your answer before generating.  It is important to generate an answer as close as possible to the TARGET WORD COUNT, which you can find in parentheses after the QUESTION (example: 8-A2: What are the social impacts of your project? (100 words), TARGET WORD COUNT is 100.).  To help with meeting the target word count goal, use the following algorithm:\n",
        "- Plan the components of your answer.\n",
        "- For each component, assign it a percentage weight of the total.  For example, if one topic or sentence accounts for half the important content in the answer, assign it a weight of 50%.\n",
        "- Generate each component of the answer, matching word counts to proportionate weight.  As in the example above, for a 100-word answer, if the first topic is assigned a weight of 50%, try to generate 1 or 2 sentences that total 50 words.\n",
        "</instructions>\n",
        "\n",
        "<question>How the uncertainties were overcome by the company under consideration?  (450 words), TARGET WORD COUNT is 450.</question>\n",
        "<context>\n",
        "-Please make a conscious effort to include specific key words associated with 'Smart city solutions' and 'IoT Integration' in your responses. These key words should be relevant to the topic being discussed and help enhance the quality and accuracy of the generated answer.\n",
        "\n",
        "</context>\n",
        "<guidance>In the first paragraph, focus on the Introduction: Briefly introduce the uncertainties faced by the subject of the answer.\n",
        "Mention the importance of identifying and resolving these uncertainties.\n",
        "Highlight the allocation of resources and commitment to resolving the uncertainties.\n",
        "\n",
        "\n",
        "In the second paragraph, focus on Uncertainty Exploration and Identification:Discuss the specific uncertainties encountered and their impact.\n",
        "Explain how research and professional expertise were used to identify these uncertainties.\n",
        "Emphasize the need for further investigation and resolution.\n",
        "\n",
        "\n",
        "In the third paragaraph, describe a Resolution Strategies and Challenges:\n",
        "Outline the strategies and approaches taken to overcome the uncertainties.\n",
        "Describe the challenges and obstacles faced during the resolution process.\n",
        "Highlight any partnerships or collaborations formed to address the uncertainties.\n",
        "\n",
        "In the fourth paragaraph, provide Specific Uncertainties and Solutions:\n",
        "Dedicate paragraphs to each major uncertainty discussed in the answer.\n",
        "Explain the nature of the uncertainty and its implications.\n",
        "Detail the specific solutions or approaches employed to resolve the uncertainty.\n",
        "Mention any iterations, modifications, or trial-and-error processes involved.\n",
        "\n",
        "\n",
        "In the fifth paragaraph, provide Discussion of Ongoing Work and Future Opportunities:\n",
        "Acknowledge that not all uncertainties have been fully resolved.\n",
        "Discuss ongoing work beyond the current timeframe or accounting period.\n",
        "Highlight the future opportunities for improvement, scalability, or research.\n",
        "</guidance>\n",
        "'''\n",
        "\n",
        "hmrc_reference=\"\"\"SCIENTIFIC OR TECHNOLOGICAL UNCERTAINTY:\n",
        "1) Scientific or technological uncertainty exists when\n",
        "knowledge of whether something is scientifically possible or\n",
        "technologically feasible, or how to achieve it in practice, is not\n",
        "readily available or deducible by a competent professional\n",
        "working in the field. This includes system uncertainty.\n",
        "Scientific or technological uncertainty will often arise from\n",
        "turning something that has already been established as\n",
        "scientifically feasible into a cost-effective, reliable and\n",
        "reproducible process, material, device, product or service.\n",
        "2) Uncertainties that can readily be resolved by a competent\n",
        "professional working in the field are not scientific or\n",
        "technological uncertainties. Similarly, improvements,\n",
        "optimisations and fine-tuning which do not materially affect\n",
        "the underlying science or technology do not constitute work\n",
        "to resolve scientific or technological uncertainty.\"\"\"\n",
        "\n",
        "\n",
        "modified_summary_q5 = apply_hmrc_guidelines(full_summary_q5, hmrc_reference)\n",
        "print(\"Modified Summary:\", modified_summary_q5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J2afq3Froe3",
        "outputId": "587d11a2-1cd3-4aa8-8c91-7449f4c9df38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "F1 Score: tensor([0.2350, 0.0416, 0.3539, 0.1536, 0.4568, 0.4035, 0.4886, 0.5031])\n",
            "F1 Mean Score: tensor(0.3293)\n",
            "F1_q5, Mean F1 q5: tensor([0.2350, 0.0416, 0.3539, 0.1536, 0.4568, 0.4035, 0.4886, 0.5031]) tensor(0.3293)\n"
          ]
        }
      ],
      "source": [
        "# Generate BERT score for modified summary - question 5\n",
        "# Include the candidate reference form the manually created output report\n",
        "\n",
        "cands_q5 = '''*(From the manually created output report, I have included the section corresponding to the question 5 for comparing the semantic similarity. I have removed this due to data privacy concerns from Grantify.)'''\n",
        "\n",
        "F1_q5, F1_mean_q5 = generate_bert_score(cands_q5, modified_summary_q5)\n",
        "\n",
        "print('F1_q5, Mean F1 q5:',F1_q5, F1_mean_q5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate DeBERTa score for summary modified by corresponding HMRC guidelines for q5\n",
        "\n",
        "similarity_matrix_deberta = compute_similarity_matrix_deberta(cands_q5, modified_summary_q5)\n",
        "\n",
        "# Print similarity matrix\n",
        "for i, candidate in enumerate(candidate_list):\n",
        "    for j, reference in enumerate(reference_list):\n",
        "        similarity_score = similarity_matrix_deberta[i][j]\n",
        "        print(f\"Similarity Score: {similarity_score:.4f}\")"
      ],
      "metadata": {
        "id": "4PvgBNWB7x6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code block for generate RoBERTa score for summary modified by corresponding HMRC guidelines for q5\n",
        "\n",
        "similarity_matrix_roberta = compute_similarity_matrix_roberta(cands_q5, modified_summary_q5)\n",
        "\n",
        "# Print similarity matrix\n",
        "for row in similarity_matrix_roberta:\n",
        "  candidate, reference, similarity_score = row\n",
        "  print(f\"Similarity score: {similarity_score:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "_rXEutbF7xsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5AjlNFNab-YX",
        "outputId": "12ee9b19-661c-4894-eeef-6c1fd2770e25"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.3.12'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check BERT installation\n",
        "import bert_score\n",
        "bert_score.__version__"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ec8bd7ba90148adaa362fe28b933396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16a844f2a27443d29e917e7d3c0f3b69",
              "IPY_MODEL_7df7bde07ef5450eaf1060e4d166b33e",
              "IPY_MODEL_1b37f16daebf4c22855511e11986be7a"
            ],
            "layout": "IPY_MODEL_e44b1ddf14ef4f49b8088cacfc2fc4a4"
          }
        },
        "16a844f2a27443d29e917e7d3c0f3b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dca5b9a8b87e4d2a8cda44cada183103",
            "placeholder": "​",
            "style": "IPY_MODEL_21873e8dcedc4b38a53cc7508695bbd6",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "7df7bde07ef5450eaf1060e4d166b33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f219a8b91e5b4ff1b52c7785ca3dc51f",
            "max": 898825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2aa012c9bf464567a1496097f1020ed1",
            "value": 898825
          }
        },
        "1b37f16daebf4c22855511e11986be7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_814d3e9670b64b1caed1adfe6eb47d5c",
            "placeholder": "​",
            "style": "IPY_MODEL_44eca686ccd04012a9920796b1bb6c58",
            "value": " 899k/899k [00:00&lt;00:00, 7.94MB/s]"
          }
        },
        "e44b1ddf14ef4f49b8088cacfc2fc4a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca5b9a8b87e4d2a8cda44cada183103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21873e8dcedc4b38a53cc7508695bbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f219a8b91e5b4ff1b52c7785ca3dc51f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aa012c9bf464567a1496097f1020ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "814d3e9670b64b1caed1adfe6eb47d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44eca686ccd04012a9920796b1bb6c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f0098d9464c4af8bf7328fdf11f1d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1363a8da9e8049868f614b5090959aba",
              "IPY_MODEL_70d39656624145ff8eec5034793e2871",
              "IPY_MODEL_2b25e46c29154ee99d656ae6ca13e560"
            ],
            "layout": "IPY_MODEL_d10dbd7afc6e4640b8cf3af1bcce016c"
          }
        },
        "1363a8da9e8049868f614b5090959aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_435ef9befd1446be9af3411bede06fc5",
            "placeholder": "​",
            "style": "IPY_MODEL_9f7692ec0083497c9870fe100a464ea5",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "70d39656624145ff8eec5034793e2871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0513d1758b97407fa23afaa42daef3e1",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8072269805944d09036ee8d0a082985",
            "value": 456318
          }
        },
        "2b25e46c29154ee99d656ae6ca13e560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6320e176eaf7412cb7a5616d2c4b19ad",
            "placeholder": "​",
            "style": "IPY_MODEL_0ca43c56a01746a988c62c94f047df8e",
            "value": " 456k/456k [00:00&lt;00:00, 15.3MB/s]"
          }
        },
        "d10dbd7afc6e4640b8cf3af1bcce016c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "435ef9befd1446be9af3411bede06fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7692ec0083497c9870fe100a464ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0513d1758b97407fa23afaa42daef3e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8072269805944d09036ee8d0a082985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6320e176eaf7412cb7a5616d2c4b19ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca43c56a01746a988c62c94f047df8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3748c1b4a6744ed9bc548d9444a86fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65bb86e04c3c45c7bc0b2bc229029637",
              "IPY_MODEL_2d6fb11ee95c4d7799da471225367361",
              "IPY_MODEL_bafdee40f6dc4174a50725779bbbd4e0"
            ],
            "layout": "IPY_MODEL_83bad556f2424ac69724dc22338c6f6e"
          }
        },
        "65bb86e04c3c45c7bc0b2bc229029637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53aee82f98b646c699216d0c13baf836",
            "placeholder": "​",
            "style": "IPY_MODEL_2bcf803878344af5bb9059a4ecb23be8",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "2d6fb11ee95c4d7799da471225367361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66d12798d08c41eaac40ca3e0e0f3bc6",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41ddfda1a5414a36a9e169db499e92f9",
            "value": 52
          }
        },
        "bafdee40f6dc4174a50725779bbbd4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4695349d14a4b5e915f65c7fd8fe9c3",
            "placeholder": "​",
            "style": "IPY_MODEL_805d3bc0b91e4935a2a2b824f8474790",
            "value": " 52.0/52.0 [00:00&lt;00:00, 2.31kB/s]"
          }
        },
        "83bad556f2424ac69724dc22338c6f6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53aee82f98b646c699216d0c13baf836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bcf803878344af5bb9059a4ecb23be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66d12798d08c41eaac40ca3e0e0f3bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ddfda1a5414a36a9e169db499e92f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4695349d14a4b5e915f65c7fd8fe9c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805d3bc0b91e4935a2a2b824f8474790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "412b795aa587401f992ee58016c1e663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26a9938c2b8e477499ba679d799a3098",
              "IPY_MODEL_37b0b8d65cea49198f75f025ceabf0c6",
              "IPY_MODEL_b1bab71e7e3645fa83943d4179969804"
            ],
            "layout": "IPY_MODEL_f3028f8db5734480b93f8e7412334335"
          }
        },
        "26a9938c2b8e477499ba679d799a3098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d3d4e87c6b64299b3433d135beccd9d",
            "placeholder": "​",
            "style": "IPY_MODEL_4f115b299bbb4c4996bd93c3bacd30f5",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "37b0b8d65cea49198f75f025ceabf0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76347ebc65f84d18b165905c6f1c113f",
            "max": 474,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec751ada77f64224aeaf17017df5e19c",
            "value": 474
          }
        },
        "b1bab71e7e3645fa83943d4179969804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1d4aa6664c649219a8e8e91066005f1",
            "placeholder": "​",
            "style": "IPY_MODEL_4e7424358e4b4d28b829b9f4537eb371",
            "value": " 474/474 [00:00&lt;00:00, 17.1kB/s]"
          }
        },
        "f3028f8db5734480b93f8e7412334335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d3d4e87c6b64299b3433d135beccd9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f115b299bbb4c4996bd93c3bacd30f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76347ebc65f84d18b165905c6f1c113f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec751ada77f64224aeaf17017df5e19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1d4aa6664c649219a8e8e91066005f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7424358e4b4d28b829b9f4537eb371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bdc0fd4cad1445da4fb0396f7d12485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c9b9709c9624b8ebb25f3cdbc63acea",
              "IPY_MODEL_bacfd963bb274f7aa189f7ab2b4d4a68",
              "IPY_MODEL_5237fbb394f8420c989236746ee52cc8"
            ],
            "layout": "IPY_MODEL_de38cd4b904c4a7586945dd9aae30d58"
          }
        },
        "5c9b9709c9624b8ebb25f3cdbc63acea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc7dbcaa50c4d0c9775fc6eff4d77f6",
            "placeholder": "​",
            "style": "IPY_MODEL_f10bb1d3c2f94ad7905f7bdeadb7c10e",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "bacfd963bb274f7aa189f7ab2b4d4a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97b1343565954902b660639a516d8dcd",
            "max": 558614189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3bbdc8ea9374e29a69c8cf32b4e356b",
            "value": 558614189
          }
        },
        "5237fbb394f8420c989236746ee52cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53107e0f24114188ba3edcd65b040c26",
            "placeholder": "​",
            "style": "IPY_MODEL_a5be0dd206c9476488c24c3dec4be359",
            "value": " 559M/559M [00:08&lt;00:00, 83.9MB/s]"
          }
        },
        "de38cd4b904c4a7586945dd9aae30d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc7dbcaa50c4d0c9775fc6eff4d77f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10bb1d3c2f94ad7905f7bdeadb7c10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97b1343565954902b660639a516d8dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3bbdc8ea9374e29a69c8cf32b4e356b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53107e0f24114188ba3edcd65b040c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5be0dd206c9476488c24c3dec4be359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ecbb59ac554cabbaf18f40d4cd126b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ab0f18e0a3043f284af3fcabbcab519",
              "IPY_MODEL_cd22d6b3bf8642dea81f0321c6a36dd5",
              "IPY_MODEL_45cfd8dfd82d4e20934365fa91b15118"
            ],
            "layout": "IPY_MODEL_f745d8b53d4840359dfa5401bf6be547"
          }
        },
        "3ab0f18e0a3043f284af3fcabbcab519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_198b3f9631b14f7f93baa341cf7881e3",
            "placeholder": "​",
            "style": "IPY_MODEL_71497ae387de4c90912a84c28770e0db",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "cd22d6b3bf8642dea81f0321c6a36dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8828fe84e40042da9193ce09d7c3d37b",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52323df5055e4040b4248810f557249c",
            "value": 898823
          }
        },
        "45cfd8dfd82d4e20934365fa91b15118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ccda1df799848c69539b7e70952357f",
            "placeholder": "​",
            "style": "IPY_MODEL_0c4fa454397c462a98d32d80d8a8b8b7",
            "value": " 899k/899k [00:00&lt;00:00, 9.73MB/s]"
          }
        },
        "f745d8b53d4840359dfa5401bf6be547": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "198b3f9631b14f7f93baa341cf7881e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71497ae387de4c90912a84c28770e0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8828fe84e40042da9193ce09d7c3d37b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52323df5055e4040b4248810f557249c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ccda1df799848c69539b7e70952357f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c4fa454397c462a98d32d80d8a8b8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc9b89bdd935417f802f21030c206f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f12d5516bb841188d84d17693fa51ff",
              "IPY_MODEL_abf19a33308a49e29e4bddceee784ca8",
              "IPY_MODEL_8e2612f7cb2d42918ed3d8829d272e9a"
            ],
            "layout": "IPY_MODEL_79a8e51f5dc140aba4b95f8c657c4858"
          }
        },
        "4f12d5516bb841188d84d17693fa51ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc9cc9de40464ae0a08e69fc829a1430",
            "placeholder": "​",
            "style": "IPY_MODEL_0506dd21daf147bf98dc3bf8218c0741",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "abf19a33308a49e29e4bddceee784ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f09c6561661b486699f3801c01618f29",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2ed6e83fe134129a794340a0e959dad",
            "value": 456318
          }
        },
        "8e2612f7cb2d42918ed3d8829d272e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feadc59b9bb545088222624b3ae39440",
            "placeholder": "​",
            "style": "IPY_MODEL_4199e5823f6a457f8c3f1c12fec48752",
            "value": " 456k/456k [00:00&lt;00:00, 18.5MB/s]"
          }
        },
        "79a8e51f5dc140aba4b95f8c657c4858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9cc9de40464ae0a08e69fc829a1430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0506dd21daf147bf98dc3bf8218c0741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f09c6561661b486699f3801c01618f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ed6e83fe134129a794340a0e959dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "feadc59b9bb545088222624b3ae39440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4199e5823f6a457f8c3f1c12fec48752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f46795560d549a187870491edb5c913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_306b293bb30e49d9ac015c022bea57d6",
              "IPY_MODEL_e5b3bfa6f49149a787d42dce37403079",
              "IPY_MODEL_cf2dad354dd345559e9a0cbf978ec642"
            ],
            "layout": "IPY_MODEL_3b9b7c3b22ea45448b501695ab571cd3"
          }
        },
        "306b293bb30e49d9ac015c022bea57d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08222869cfd54adf8327231dbc349052",
            "placeholder": "​",
            "style": "IPY_MODEL_41612e156a154ef0b111d1eb70511910",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "e5b3bfa6f49149a787d42dce37403079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f28b318d1a049228ac5785e857ab53e",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb10bc208c4b4f40a3ef8d5dd7fdf2c6",
            "value": 481
          }
        },
        "cf2dad354dd345559e9a0cbf978ec642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5999978cb1748318543f4c042a784ab",
            "placeholder": "​",
            "style": "IPY_MODEL_ef8dbdfe94084ee6a9a7d6772cdb503d",
            "value": " 481/481 [00:00&lt;00:00, 31.3kB/s]"
          }
        },
        "3b9b7c3b22ea45448b501695ab571cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08222869cfd54adf8327231dbc349052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41612e156a154ef0b111d1eb70511910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f28b318d1a049228ac5785e857ab53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb10bc208c4b4f40a3ef8d5dd7fdf2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5999978cb1748318543f4c042a784ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef8dbdfe94084ee6a9a7d6772cdb503d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0733322784a740c8b8c1a77e19eadbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59c2a1ce4dce42c9a7e8719eba83c728",
              "IPY_MODEL_45a0a1c727ce4bce8c6013b613ae9940",
              "IPY_MODEL_1b245470371e4b24a8c02fb35a8aac94"
            ],
            "layout": "IPY_MODEL_d3a544da2a4e4b4d9234af21fe5ccb8a"
          }
        },
        "59c2a1ce4dce42c9a7e8719eba83c728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6f035f3a215485e8522b45cf081d9d2",
            "placeholder": "​",
            "style": "IPY_MODEL_2902dad3d41e4526b93ff16fcf96fe08",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "45a0a1c727ce4bce8c6013b613ae9940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39e48843854c4baaa6c3ba8504b5a799",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4348fc0faf543e5a2e89e1d165a35f9",
            "value": 498818054
          }
        },
        "1b245470371e4b24a8c02fb35a8aac94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf4db1ba2114dd4b560fb2003259b8c",
            "placeholder": "​",
            "style": "IPY_MODEL_d7f576b54a8346b3890b22c6e2a3ebdc",
            "value": " 499M/499M [00:05&lt;00:00, 96.8MB/s]"
          }
        },
        "d3a544da2a4e4b4d9234af21fe5ccb8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f035f3a215485e8522b45cf081d9d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2902dad3d41e4526b93ff16fcf96fe08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39e48843854c4baaa6c3ba8504b5a799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4348fc0faf543e5a2e89e1d165a35f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdf4db1ba2114dd4b560fb2003259b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7f576b54a8346b3890b22c6e2a3ebdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}